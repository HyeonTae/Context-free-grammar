{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Parameter\n",
    "- Attention = False\n",
    "- Drop out = 0.2\n",
    "- Teacher Forcing Ratio = 0.5\n",
    "- Layer = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages\n",
    "\n",
    "import useful packages for experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hyeontae/hyeontae/venv/lib/python3.5/site-packages/torch/nn/functional.py:52: UserWarning: size_average and reduce args will be deprecated, please use reduction='elementwise_mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/home/hyeontae/hyeontae/venv/lib/python3.5/site-packages/torch/nn/functional.py:52: UserWarning: size_average and reduce args will be deprecated, please use reduction='elementwise_mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import argparse\n",
    "import logging\n",
    "\n",
    "import torch\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import torchtext\n",
    "\n",
    "from trainer.supervised_trainer import SupervisedTrainer\n",
    "from models.encoderRNN import EncoderRNN\n",
    "from models.decoderRNN import DecoderRNN\n",
    "from models.seq2seq import Seq2seq\n",
    "from loss.loss import Perplexity\n",
    "from optim.optim import Optimizer\n",
    "from dataset import fields\n",
    "from evaluator.predictor import Predictor\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"data/grammar_data_N100_train.txt\"\n",
    "dev_path = \"data/grammar_data_N100_test.txt\"\n",
    "log_level = 'info'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Log format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG_FORMAT = '%(asctime)s %(levelname)-6s %(message)s'\n",
    "logging.basicConfig(format=LOG_FORMAT, level=getattr(logging, log_level.upper()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = fields.SourceField()\n",
    "tgt = fields.TargetField()\n",
    "max_len = 102\n",
    "def len_filter(example):\n",
    "    return len(example.src) <= max_len and len(example.tgt) <= max_len\n",
    "train = torchtext.data.TabularDataset(\n",
    "    path=train_path, format='tsv',\n",
    "    fields=[('src', src), ('tgt', tgt)],\n",
    "    filter_pred=len_filter\n",
    ")\n",
    "dev = torchtext.data.TabularDataset(\n",
    "    path=dev_path, format='tsv',\n",
    "    fields=[('src', src), ('tgt', tgt)],\n",
    "    filter_pred=len_filter\n",
    ")\n",
    "src.build_vocab(train)\n",
    "tgt.build_vocab(train)\n",
    "input_vocab = src.vocab\n",
    "output_vocab = tgt.vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hyeontae/hyeontae/venv/lib/python3.5/site-packages/torch/nn/functional.py:52: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "weight = torch.ones(len(tgt.vocab))\n",
    "pad = tgt.vocab.stoi[tgt.pad_token]\n",
    "loss = Perplexity(weight, pad)\n",
    "if torch.cuda.is_available():\n",
    "    loss.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variable definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\n"
     ]
    }
   ],
   "source": [
    "seq2seq = None\n",
    "optimizer = \"Adam\"\n",
    "\n",
    "hidden_sizes = list(range(50, 51, 4))\n",
    "print(hidden_sizes)\n",
    "error_rate = []\n",
    "accuracy = []\n",
    "losses = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hyeontae/hyeontae/venv/lib/python3.5/site-packages/torch/nn/modules/rnn.py:38: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n",
      "2019-01-29 15:59:45,622 INFO   Optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.001\n",
      "    weight_decay: 0\n",
      "), Scheduler: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden size is 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-29 16:03:39,468 INFO   Finished epoch 1: Train loss: 18.3117, Dev loss: 15.8628, Accuracy(Character): 0.2787, Accuracy(Word): 0.0000\n",
      "2019-01-29 16:08:11,704 INFO   Finished epoch 2: Train loss: 4.3785, Dev loss: 4.8178, Accuracy(Character): 0.4472, Accuracy(Word): 0.0001\n",
      "2019-01-29 16:12:50,761 INFO   Finished epoch 3: Train loss: 2.9062, Dev loss: 4.1358, Accuracy(Character): 0.4886, Accuracy(Word): 0.0002\n",
      "2019-01-29 16:17:23,995 INFO   Finished epoch 4: Train loss: 2.4623, Dev loss: 3.0170, Accuracy(Character): 0.5738, Accuracy(Word): 0.0004\n",
      "2019-01-29 16:21:52,287 INFO   Finished epoch 5: Train loss: 2.2796, Dev loss: 2.9074, Accuracy(Character): 0.5887, Accuracy(Word): 0.0018\n",
      "2019-01-29 16:26:30,109 INFO   Finished epoch 6: Train loss: 2.1868, Dev loss: 3.7130, Accuracy(Character): 0.5492, Accuracy(Word): 0.0052\n",
      "2019-01-29 16:31:06,704 INFO   Finished epoch 7: Train loss: 2.0524, Dev loss: 2.6404, Accuracy(Character): 0.6133, Accuracy(Word): 0.0053\n",
      "2019-01-29 16:35:41,134 INFO   Finished epoch 8: Train loss: 2.0382, Dev loss: 2.4587, Accuracy(Character): 0.6369, Accuracy(Word): 0.0055\n",
      "2019-01-29 16:40:12,395 INFO   Finished epoch 9: Train loss: 1.9804, Dev loss: 2.4256, Accuracy(Character): 0.6437, Accuracy(Word): 0.0053\n",
      "2019-01-29 16:44:53,095 INFO   Finished epoch 10: Train loss: 1.9652, Dev loss: 2.5102, Accuracy(Character): 0.6395, Accuracy(Word): 0.0059\n",
      "2019-01-29 16:49:28,350 INFO   Finished epoch 11: Train loss: 1.9322, Dev loss: 2.4113, Accuracy(Character): 0.6356, Accuracy(Word): 0.0052\n",
      "2019-01-29 16:53:58,970 INFO   Finished epoch 12: Train loss: 1.8594, Dev loss: 2.5009, Accuracy(Character): 0.6334, Accuracy(Word): 0.0053\n",
      "2019-01-29 16:58:36,139 INFO   Finished epoch 13: Train loss: 1.8217, Dev loss: 2.1708, Accuracy(Character): 0.6831, Accuracy(Word): 0.0062\n",
      "2019-01-29 17:03:10,767 INFO   Finished epoch 14: Train loss: 1.7906, Dev loss: 2.1079, Accuracy(Character): 0.6889, Accuracy(Word): 0.0055\n",
      "2019-01-29 17:07:44,622 INFO   Finished epoch 15: Train loss: 1.7730, Dev loss: 2.0941, Accuracy(Character): 0.6893, Accuracy(Word): 0.0088\n",
      "2019-01-29 17:12:14,181 INFO   Finished epoch 16: Train loss: 1.7492, Dev loss: 2.0500, Accuracy(Character): 0.7019, Accuracy(Word): 0.0102\n",
      "2019-01-29 17:16:49,876 INFO   Finished epoch 17: Train loss: 1.7489, Dev loss: 2.0644, Accuracy(Character): 0.6947, Accuracy(Word): 0.0067\n",
      "2019-01-29 17:21:28,979 INFO   Finished epoch 18: Train loss: 1.7308, Dev loss: 1.9567, Accuracy(Character): 0.7139, Accuracy(Word): 0.0091\n",
      "2019-01-29 17:26:01,382 INFO   Finished epoch 19: Train loss: 1.6886, Dev loss: 1.9847, Accuracy(Character): 0.7134, Accuracy(Word): 0.0089\n",
      "2019-01-29 17:30:31,134 INFO   Finished epoch 20: Train loss: 1.6699, Dev loss: 2.1451, Accuracy(Character): 0.6644, Accuracy(Word): 0.0096\n"
     ]
    }
   ],
   "source": [
    "for i in hidden_sizes:\n",
    "    print(\"Hidden size is %d\" % i)\n",
    "    hidden_size = i\n",
    "    bidirectional = True\n",
    "    encoder = EncoderRNN(len(src.vocab), max_len, hidden_size,\n",
    "                        bidirectional=bidirectional, variable_lengths=True)\n",
    "    decoder = DecoderRNN(len(tgt.vocab), max_len, hidden_size * 2 if bidirectional else hidden_size,\n",
    "                        dropout_p=0.2, use_attention=False, bidirectional=bidirectional,\n",
    "                        eos_id=tgt.eos_id, sos_id=tgt.sos_id)\n",
    "    seq2seq = Seq2seq(encoder, decoder)\n",
    "    if torch.cuda.is_available():\n",
    "        seq2seq.cuda()\n",
    "\n",
    "    for param in seq2seq.parameters():\n",
    "        param.data.uniform_(-0.08, 0.08)\n",
    "\n",
    "    # train\n",
    "    t = SupervisedTrainer(loss=loss, batch_size=32,\n",
    "                        checkpoint_every=50,\n",
    "                        print_every=100)\n",
    "\n",
    "    seq2seq, ave_loss, character_accuracy = t.train(seq2seq, train,\n",
    "                                                    num_epochs=50, dev_data=dev,\n",
    "                                                    optimizer=optimizer,\n",
    "                                                    teacher_forcing_ratio=0.5)\n",
    "\n",
    "    losses.append(ave_loss/100)\n",
    "    error_rate.append(1 - character_accuracy)\n",
    "    accuracy.append(character_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(seq2seq.state_dict(), 'log/100N_no_att_model_save.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
