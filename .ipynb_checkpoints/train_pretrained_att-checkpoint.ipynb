{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Parameter\n",
    "- Attention = False\n",
    "- Drop out = 0.2\n",
    "- Teacher Forcing Ratio = 0.5\n",
    "- Layer = 1\n",
    "- Hidden unit = 50\n",
    "- Batch size = 32\n",
    "- Pretrain Epochs = 20\n",
    "- Train Epochs = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages\n",
    "\n",
    "import useful packages for experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hyeontae/hyeontae/venv/lib/python3.5/site-packages/torch/nn/functional.py:52: UserWarning: size_average and reduce args will be deprecated, please use reduction='elementwise_mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/home/hyeontae/hyeontae/venv/lib/python3.5/site-packages/torch/nn/functional.py:52: UserWarning: size_average and reduce args will be deprecated, please use reduction='elementwise_mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import argparse\n",
    "import logging\n",
    "\n",
    "import torch\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import torchtext\n",
    "\n",
    "from trainer.supervised_trainer import SupervisedTrainer\n",
    "from models.encoderRNN import EncoderRNN\n",
    "from models.decoderRNN import DecoderRNN\n",
    "from models.seq2seq import Seq2seq\n",
    "from loss.loss import Perplexity\n",
    "from optim.optim import Optimizer\n",
    "from dataset import fields\n",
    "from evaluator.predictor import Predictor\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Log format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_level = 'info'\n",
    "LOG_FORMAT = '%(asctime)s %(levelname)-6s %(message)s'\n",
    "logging.basicConfig(format=LOG_FORMAT, level=getattr(logging, log_level.upper()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretrain - Data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrain_train_path = \"data/grammar_data_N50_train.txt\"\n",
    "pretrain_dev_path = \"data/grammar_data_N50_test.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train - Data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"data/grammar_data_N100_train.txt\"\n",
    "dev_path = \"data/grammar_data_N100_test.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretrain - Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrain_src = fields.SourceField()\n",
    "pretrain_tgt = fields.TargetField()\n",
    "max_len = 104\n",
    "def len_filter(example):\n",
    "    return len(example.src) <= max_len and len(example.tgt) <= max_len\n",
    "pretrain_train = torchtext.data.TabularDataset(\n",
    "    path=pretrain_train_path, format='tsv',\n",
    "    fields=[('src', pretrain_src), ('tgt', pretrain_tgt)],\n",
    "    filter_pred=len_filter\n",
    ")\n",
    "pretrain_dev = torchtext.data.TabularDataset(\n",
    "    path=pretrain_dev_path, format='tsv',\n",
    "    fields=[('src', pretrain_src), ('tgt', pretrain_tgt)],\n",
    "    filter_pred=len_filter\n",
    ")\n",
    "pretrain_src.build_vocab(pretrain_train)\n",
    "pretrain_tgt.build_vocab(pretrain_train)\n",
    "pretrain_input_vocab = pretrain_src.vocab\n",
    "pretrain_output_vocab = pretrain_tgt.vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train - Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = fields.SourceField()\n",
    "tgt = fields.TargetField()\n",
    "max_len = 104\n",
    "def len_filter(example):\n",
    "    return len(example.src) <= max_len and len(example.tgt) <= max_len\n",
    "train = torchtext.data.TabularDataset(\n",
    "    path=train_path, format='tsv',\n",
    "    fields=[('src', src), ('tgt', tgt)],\n",
    "    filter_pred=len_filter\n",
    ")\n",
    "dev = torchtext.data.TabularDataset(\n",
    "    path=dev_path, format='tsv',\n",
    "    fields=[('src', src), ('tgt', tgt)],\n",
    "    filter_pred=len_filter\n",
    ")\n",
    "src.build_vocab(train)\n",
    "tgt.build_vocab(train)\n",
    "input_vocab = src.vocab\n",
    "output_vocab = tgt.vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretrain - Prepare loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hyeontae/hyeontae/venv/lib/python3.5/site-packages/torch/nn/functional.py:52: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "pretrain_weight = torch.ones(len(pretrain_tgt.vocab))\n",
    "pretrain_pad = pretrain_tgt.vocab.stoi[pretrain_tgt.pad_token]\n",
    "pretrain_loss = Perplexity(pretrain_weight, pretrain_pad)\n",
    "if torch.cuda.is_available():\n",
    "    pretrain_loss.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train - Prepare loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = torch.ones(len(tgt.vocab))\n",
    "pad = tgt.vocab.stoi[tgt.pad_token]\n",
    "loss = Perplexity(weight, pad)\n",
    "if torch.cuda.is_available():\n",
    "    loss.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variable definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\n"
     ]
    }
   ],
   "source": [
    "seq2seq = None\n",
    "optimizer = \"Adam\"\n",
    "\n",
    "hidden_sizes = list(range(50, 51, 4))\n",
    "print(hidden_sizes)\n",
    "error_rate = []\n",
    "accuracy = []\n",
    "losses = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hyeontae/hyeontae/venv/lib/python3.5/site-packages/torch/nn/modules/rnn.py:38: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n",
      "2019-01-28 09:46:48,258 INFO   Optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.001\n",
      "    weight_decay: 0\n",
      "), Scheduler: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden size is 50\n",
      "6\n",
      "49\n",
      "6\n",
      "49\n",
      "pretrain..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-28 09:48:48,754 INFO   Finished epoch 1: Train loss: 7.3495, Dev loss: 3.7483, Accuracy(Character): 0.4791, Accuracy(Word): 0.0000\n",
      "2019-01-28 09:50:52,377 INFO   Finished epoch 2: Train loss: 2.2438, Dev loss: 2.2616, Accuracy(Character): 0.6567, Accuracy(Word): 0.0001\n",
      "2019-01-28 09:52:53,319 INFO   Finished epoch 3: Train loss: 1.8001, Dev loss: 2.2170, Accuracy(Character): 0.6837, Accuracy(Word): 0.0000\n",
      "2019-01-28 09:54:56,199 INFO   Finished epoch 4: Train loss: 1.6672, Dev loss: 1.7612, Accuracy(Character): 0.7712, Accuracy(Word): 0.0037\n",
      "2019-01-28 09:56:58,167 INFO   Finished epoch 5: Train loss: 1.5743, Dev loss: 1.6382, Accuracy(Character): 0.7970, Accuracy(Word): 0.0035\n",
      "2019-01-28 09:58:59,780 INFO   Finished epoch 6: Train loss: 1.4938, Dev loss: 1.8982, Accuracy(Character): 0.7472, Accuracy(Word): 0.0103\n",
      "2019-01-28 10:01:02,027 INFO   Finished epoch 7: Train loss: 1.4620, Dev loss: 1.6906, Accuracy(Character): 0.7922, Accuracy(Word): 0.0046\n",
      "2019-01-28 10:03:05,127 INFO   Finished epoch 8: Train loss: 1.4169, Dev loss: 1.5130, Accuracy(Character): 0.8293, Accuracy(Word): 0.0173\n",
      "2019-01-28 10:05:06,582 INFO   Finished epoch 9: Train loss: 1.3866, Dev loss: 1.4148, Accuracy(Character): 0.8570, Accuracy(Word): 0.0114\n",
      "2019-01-28 10:07:07,705 INFO   Finished epoch 10: Train loss: 1.3669, Dev loss: 1.4327, Accuracy(Character): 0.8521, Accuracy(Word): 0.0116\n",
      "2019-01-28 10:09:11,100 INFO   Finished epoch 11: Train loss: 1.3396, Dev loss: 1.5438, Accuracy(Character): 0.8335, Accuracy(Word): 0.0101\n",
      "2019-01-28 10:11:14,563 INFO   Finished epoch 12: Train loss: 1.3281, Dev loss: 1.4428, Accuracy(Character): 0.8497, Accuracy(Word): 0.0036\n",
      "2019-01-28 10:13:16,364 INFO   Finished epoch 13: Train loss: 1.3049, Dev loss: 1.3292, Accuracy(Character): 0.8833, Accuracy(Word): 0.0168\n",
      "2019-01-28 10:15:18,814 INFO   Finished epoch 14: Train loss: 1.2919, Dev loss: 1.3337, Accuracy(Character): 0.8818, Accuracy(Word): 0.0175\n",
      "2019-01-28 10:17:21,924 INFO   Finished epoch 15: Train loss: 1.2830, Dev loss: 1.3081, Accuracy(Character): 0.8916, Accuracy(Word): 0.0103\n",
      "2019-01-28 10:19:23,743 INFO   Finished epoch 16: Train loss: 1.2591, Dev loss: 1.6252, Accuracy(Character): 0.8257, Accuracy(Word): 0.0178\n",
      "2019-01-28 10:21:25,514 INFO   Finished epoch 17: Train loss: 1.2652, Dev loss: 1.3941, Accuracy(Character): 0.8719, Accuracy(Word): 0.0171\n",
      "2019-01-28 10:23:27,284 INFO   Finished epoch 18: Train loss: 1.2447, Dev loss: 1.2480, Accuracy(Character): 0.9104, Accuracy(Word): 0.0101\n",
      "2019-01-28 10:25:30,082 INFO   Finished epoch 19: Train loss: 1.2211, Dev loss: 1.2610, Accuracy(Character): 0.9063, Accuracy(Word): 0.0229\n",
      "2019-01-28 10:27:31,448 INFO   Finished epoch 20: Train loss: 1.2111, Dev loss: 1.4636, Accuracy(Character): 0.8632, Accuracy(Word): 0.0176\n",
      "2019-01-28 10:27:31,538 INFO   Optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.001\n",
      "    weight_decay: 0\n",
      "), Scheduler: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-28 10:31:13,785 INFO   Finished epoch 1: Train loss: 69713.0073, Dev loss: 2.8082, Accuracy(Character): 0.5934, Accuracy(Word): 0.0000\n",
      "2019-01-28 10:34:58,774 INFO   Finished epoch 2: Train loss: 2.1493, Dev loss: 2.4001, Accuracy(Character): 0.6493, Accuracy(Word): 0.0000\n",
      "2019-01-28 10:38:37,861 INFO   Finished epoch 3: Train loss: 1.9307, Dev loss: 2.3626, Accuracy(Character): 0.6486, Accuracy(Word): 0.0000\n",
      "2019-01-28 10:42:18,254 INFO   Finished epoch 4: Train loss: 1.8412, Dev loss: 2.0419, Accuracy(Character): 0.7069, Accuracy(Word): 0.0000\n",
      "2019-01-28 10:46:00,712 INFO   Finished epoch 5: Train loss: 1.7993, Dev loss: 2.0158, Accuracy(Character): 0.7157, Accuracy(Word): 0.0000\n",
      "2019-01-28 10:49:41,636 INFO   Finished epoch 6: Train loss: 1.7802, Dev loss: 1.9542, Accuracy(Character): 0.7260, Accuracy(Word): 0.0000\n",
      "2019-01-28 10:53:22,323 INFO   Finished epoch 7: Train loss: 1.7184, Dev loss: 2.0350, Accuracy(Character): 0.7192, Accuracy(Word): 0.0000\n",
      "2019-01-28 10:57:07,086 INFO   Finished epoch 8: Train loss: 1.7037, Dev loss: 1.8499, Accuracy(Character): 0.7423, Accuracy(Word): 0.0091\n",
      "2019-01-28 11:00:48,807 INFO   Finished epoch 9: Train loss: 1.6685, Dev loss: 2.5636, Accuracy(Character): 0.6577, Accuracy(Word): 0.0092\n",
      "2019-01-28 11:04:27,940 INFO   Finished epoch 10: Train loss: 1.6712, Dev loss: 2.0519, Accuracy(Character): 0.7208, Accuracy(Word): 0.0000\n",
      "2019-01-28 11:08:12,430 INFO   Finished epoch 11: Train loss: 1.6555, Dev loss: 1.7771, Accuracy(Character): 0.7584, Accuracy(Word): 0.0000\n",
      "2019-01-28 11:11:54,534 INFO   Finished epoch 12: Train loss: 1.5971, Dev loss: 2.0220, Accuracy(Character): 0.7194, Accuracy(Word): 0.0000\n",
      "2019-01-28 11:15:37,575 INFO   Finished epoch 13: Train loss: 1.5960, Dev loss: 1.7622, Accuracy(Character): 0.7668, Accuracy(Word): 0.0000\n",
      "2019-01-28 11:19:21,906 INFO   Finished epoch 14: Train loss: 1.5838, Dev loss: 1.7393, Accuracy(Character): 0.7622, Accuracy(Word): 0.0000\n",
      "2019-01-28 11:23:06,733 INFO   Finished epoch 15: Train loss: 1.5868, Dev loss: 3.3543, Accuracy(Character): 0.5947, Accuracy(Word): 0.0000\n",
      "2019-01-28 11:26:46,482 INFO   Finished epoch 16: Train loss: 1.5417, Dev loss: 1.6480, Accuracy(Character): 0.7867, Accuracy(Word): 0.0000\n",
      "2019-01-28 11:30:30,052 INFO   Finished epoch 17: Train loss: 1.5677, Dev loss: 2.1383, Accuracy(Character): 0.7048, Accuracy(Word): 0.0000\n",
      "2019-01-28 11:34:12,810 INFO   Finished epoch 18: Train loss: 1.5431, Dev loss: 2.8690, Accuracy(Character): 0.6647, Accuracy(Word): 0.0000\n",
      "2019-01-28 11:37:56,761 INFO   Finished epoch 19: Train loss: 1.5412, Dev loss: 1.7050, Accuracy(Character): 0.7777, Accuracy(Word): 0.0000\n",
      "2019-01-28 11:41:40,758 INFO   Finished epoch 20: Train loss: 1.5244, Dev loss: 2.0367, Accuracy(Character): 0.7313, Accuracy(Word): 0.0000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in hidden_sizes:\n",
    "    print(\"Hidden size is %d\" % i)\n",
    "    hidden_size = i\n",
    "    bidirectional = True\n",
    "    print(len(pretrain_src.vocab))\n",
    "    print(len(pretrain_tgt.vocab))\n",
    "    print(len(src.vocab))\n",
    "    print(len(tgt.vocab))\n",
    "    encoder = EncoderRNN(len(pretrain_src.vocab), max_len, hidden_size,\n",
    "                        bidirectional=bidirectional, variable_lengths=True)\n",
    "    decoder = DecoderRNN(len(pretrain_tgt.vocab), max_len, hidden_size * 2 if bidirectional else hidden_size,\n",
    "                        dropout_p=0.2, use_attention=False, bidirectional=bidirectional,\n",
    "                        eos_id=pretrain_tgt.eos_id, sos_id=pretrain_tgt.sos_id)\n",
    "    seq2seq = Seq2seq(encoder, decoder)\n",
    "    if torch.cuda.is_available():\n",
    "        seq2seq.cuda()\n",
    "\n",
    "    for param in seq2seq.parameters():\n",
    "        param.data.uniform_(-0.08, 0.08)\n",
    "\n",
    "    # train\n",
    "    t = SupervisedTrainer(loss=pretrain_loss, batch_size=32,\n",
    "                        checkpoint_every=50,\n",
    "                        print_every=100,\n",
    "                        hidden_size=hidden_size,\n",
    "                        fig_path=\"log/plot/pretrained_no_att\")\n",
    "    print(\"pretrain..\")\n",
    "\n",
    "    seq2seq, ave_loss, character_accuracy = t.train(seq2seq, pretrain_train,\n",
    "                                                    num_epochs=20, dev_data=pretrain_dev,\n",
    "                                                    optimizer=optimizer,\n",
    "                                                    teacher_forcing_ratio=0.5)\n",
    "    \n",
    "    print(\"train..\")\n",
    "    seq2seq, ave_loss, character_accuracy = t.train(seq2seq, train,\n",
    "                                                    num_epochs=20, dev_data=dev,\n",
    "                                                    optimizer=optimizer,\n",
    "                                                    teacher_forcing_ratio=0.5)\n",
    "\n",
    "    losses.append(ave_loss/100)\n",
    "    error_rate.append(1 - character_accuracy)\n",
    "    accuracy.append(character_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(seq2seq.state_dict(), 'log/pretrained_model_save.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
