{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Parameter\n",
    "- Attention = Luong\n",
    "- Teacher Forcing Ratio = 0.5\n",
    "- Layer = 1\n",
    "- Batch size = 32\n",
    "- Drop out = 0.2\n",
    "- Hidden unit = 50\n",
    "- Epochs = 50\n",
    "- N = 50\n",
    "- Data Length = 100K\n",
    "- Data = [Palindrome, Double]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages\n",
    "\n",
    "import useful packages for experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hyeontae/hyeontae/venv/lib/python3.5/site-packages/torch/nn/functional.py:52: UserWarning: size_average and reduce args will be deprecated, please use reduction='elementwise_mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/home/hyeontae/hyeontae/venv/lib/python3.5/site-packages/torch/nn/functional.py:52: UserWarning: size_average and reduce args will be deprecated, please use reduction='elementwise_mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import argparse\n",
    "import logging\n",
    "\n",
    "import torch\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import torchtext\n",
    "\n",
    "from trainer.supervised_trainer import SupervisedTrainer\n",
    "from trainer.supervised_trainer_unmatching import SupervisedTrainer_unmatching\n",
    "from models.encoderRNN import EncoderRNN\n",
    "from models.decoderRNN import DecoderRNN\n",
    "from models.seq2seq import Seq2seq\n",
    "from loss.loss import Perplexity\n",
    "from optim.optim import Optimizer\n",
    "from dataset import fields\n",
    "from evaluator.predictor import Predictor\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Log format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_level = 'info'\n",
    "LOG_FORMAT = '%(asctime)s %(levelname)-6s %(message)s'\n",
    "logging.basicConfig(format=LOG_FORMAT, level=getattr(logging, log_level.upper()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name = [\"Palindrome_double\", \"Palindrome_double\"]\n",
    "data_path = [\"palindrome_data\", \"palindrome_data_double\"]\n",
    "character_accuracy = []\n",
    "sentance_accuracy = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data : Palindrome_double\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hyeontae/hyeontae/venv/lib/python3.5/site-packages/torch/nn/functional.py:52: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/home/hyeontae/hyeontae/venv/lib/python3.5/site-packages/torch/nn/modules/rnn.py:38: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n",
      "2019-02-26 07:50:49,358 INFO   Optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.001\n",
      "    weight_decay: 0\n",
      "), Scheduler: None\n",
      "/home/hyeontae/hyeontae/venv/lib/python3.5/site-packages/torch/nn/functional.py:995: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    }
   ],
   "source": [
    "for i, j in zip(data_name, data_path):\n",
    "    print(\"data : %s\" % i)\n",
    "    train_path = j + \"/data_train.txt\"\n",
    "    dev_path = j + \"/data_test2.txt\"\n",
    "\n",
    "    src = fields.SourceField()\n",
    "    tgt = fields.TargetField()\n",
    "    max_len = 104\n",
    "    def len_filter(example):\n",
    "        return len(example.src) <= max_len and len(example.tgt) <= max_len\n",
    "    train = torchtext.data.TabularDataset(\n",
    "        path=train_path, format='tsv',\n",
    "        fields=[('src', src), ('tgt', tgt)],\n",
    "        filter_pred=len_filter\n",
    "    )\n",
    "    dev = torchtext.data.TabularDataset(\n",
    "        path=dev_path, format='tsv',\n",
    "        fields=[('src', src), ('tgt', tgt)],\n",
    "        filter_pred=len_filter\n",
    "    )\n",
    "    src.build_vocab(train)\n",
    "    tgt.build_vocab(train)\n",
    "    input_vocab = src.vocab\n",
    "    output_vocab = tgt.vocab\n",
    "\n",
    "    weight = torch.ones(len(tgt.vocab))\n",
    "    pad = tgt.vocab.stoi[tgt.pad_token]\n",
    "    loss = Perplexity(weight, pad)\n",
    "    if torch.cuda.is_available():\n",
    "        loss.cuda()\n",
    "    \n",
    "    optimizer = \"Adam\"\n",
    "    hidden_size = 50\n",
    "    bidirectional = True\n",
    "\n",
    "    seq2seq = None\n",
    "    encoder = EncoderRNN(len(src.vocab), max_len, hidden_size,\n",
    "                         bidirectional=bidirectional, variable_lengths=True)\n",
    "    decoder = DecoderRNN(len(tgt.vocab), max_len, hidden_size * 2 if bidirectional else hidden_size,\n",
    "                         dropout_p=0.2, use_attention=\"Luong\", bidirectional=bidirectional,\n",
    "                         eos_id=tgt.eos_id, sos_id=tgt.sos_id)\n",
    "    seq2seq = Seq2seq(encoder, decoder)\n",
    "    if torch.cuda.is_available():\n",
    "        seq2seq.cuda()\n",
    "\n",
    "    for param in seq2seq.parameters():\n",
    "        param.data.uniform_(-0.08, 0.08)\n",
    "\n",
    "    # train\n",
    "    t = SupervisedTrainer(loss=loss, batch_size=32,\n",
    "                          checkpoint_every=50,\n",
    "                          print_every=100,\n",
    "                          hidden_size=hidden_size,\n",
    "                          fig_path=\"log/plot/\" + i)\n",
    "\n",
    "    seq2seq, ave_loss, character_accuracy_list, sentance_accuracy_list = t.train(seq2seq, train,\n",
    "                                                                             num_epochs=50, dev_data=dev,\n",
    "                                                                             optimizer=optimizer,\n",
    "                                                                             teacher_forcing_ratio=0.5)\n",
    "\n",
    "    character_accuracy.append(character_accuracy_list)\n",
    "    sentance_accuracy.append(sentance_accuracy_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = list(range(1, 51, 1))\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.grid(True)\n",
    "plt.plot(epochs[1::4], character_accuracy[0][1::4], color=\"b\", LineWidth=4, label=\"5 Character Types\")\n",
    "plt.plot(epochs[1::4], character_accuracy[1][1::4], color=\"g\", LineWidth=4, label=\"10 Character Types\")\n",
    "plt.legend(loc=\"best\", fontsize=18)\n",
    "plt.xlabel('Epoch', fontsize=24)\n",
    "plt.ylabel('Character Accuracy', fontsize=24)\n",
    "plt.title('Palindrome', fontsize=35, fontweight=560)\n",
    "plt.savefig('log/plot/Palindrome_double_to_character_accuracy.png')\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.grid(True)\n",
    "plt.plot(epochs[1::4], sentance_accuracy[0][::5], color=\"b\", LineWidth=4, label=\"5 Character Types\")\n",
    "plt.plot(epochs[1::4], sentance_accuracy[1][1::4], color=\"g\", LineWidth=4, label=\"10 Character Types\")\n",
    "plt.legend(loc=\"best\", fontsize=18)\n",
    "plt.xlabel('Epoch', fontsize=24)\n",
    "plt.ylabel('Sentance Accuracy', fontsize=24)\n",
    "plt.title('Palindrome', fontsize=35, fontweight=560)\n",
    "plt.savefig('log/plot/Palindrome_double_to_sentance_accuracy.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
