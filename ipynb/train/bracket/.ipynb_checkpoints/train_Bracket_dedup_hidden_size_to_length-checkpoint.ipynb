{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Parameter\n",
    "- Attention = Luong\n",
    "- Teacher Forcing Ratio = 0.5\n",
    "- Layer = 1\n",
    "- Batch size = 32\n",
    "- Drop out = 0.2\n",
    "- Hidden unit = [2, 50]\n",
    "- Depth = [1, 32]\n",
    "- Epochs = 100\n",
    "- N = 100\n",
    "- Data = 100K\n",
    "- Deduplication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages\n",
    "\n",
    "import useful packages for experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hyeontae/hyeontae/venv2/lib/python3.5/site-packages/torch/nn/_reduction.py:49: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import argparse\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import torchtext\n",
    "\n",
    "sys.path.append(os.path.dirname(os.path.abspath(os.path.dirname(os.path.abspath(os.path.dirname(os.path.abspath(os.path.dirname('__file__'))))))))\n",
    "\n",
    "from trainer.supervised_trainer_without_eval import SupervisedTrainer_without_eval\n",
    "from models.encoderRNN import EncoderRNN\n",
    "from models.decoderRNN import DecoderRNN\n",
    "from models.seq2seq import Seq2seq\n",
    "from loss.loss import Perplexity\n",
    "from optim.optim import Optimizer\n",
    "from dataset import fields\n",
    "from evaluator.evaluator import Evaluator\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Log format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_level = 'info'\n",
    "LOG_FORMAT = '%(asctime)s %(levelname)-6s %(message)s'\n",
    "logging.basicConfig(format=LOG_FORMAT, level=getattr(logging, log_level.upper()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"../../../data/bracket_dedup/K100/data_train.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = fields.SourceField()\n",
    "tgt = fields.TargetField()\n",
    "max_len = 104\n",
    "def len_filter(example):\n",
    "    return len(example.src) <= max_len and len(example.tgt) <= max_len\n",
    "train = torchtext.data.TabularDataset(\n",
    "    path=train_path, format='tsv',\n",
    "    fields=[('src', src), ('tgt', tgt)],\n",
    "    filter_pred=len_filter\n",
    ")\n",
    "src.build_vocab(train)\n",
    "tgt.build_vocab(train)\n",
    "input_vocab = src.vocab\n",
    "output_vocab = tgt.vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hyeontae/hyeontae/venv2/lib/python3.5/site-packages/torch/nn/_reduction.py:49: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "weight = torch.ones(len(tgt.vocab))\n",
    "pad = tgt.vocab.stoi[tgt.pad_token]\n",
    "loss = Perplexity(weight, pad)\n",
    "if torch.cuda.is_available():\n",
    "    loss.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variable definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 6, 10, 14, 18, 22, 26, 30, 34, 38, 42, 46, 50]\n"
     ]
    }
   ],
   "source": [
    "optimizer = \"Adam\"\n",
    "hidden_sizes = list(range(2, 51, 4))\n",
    "depth_list = []\n",
    "bidirectional = True\n",
    "print(hidden_sizes)\n",
    "evaluator = Evaluator(loss=loss, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hyeontae/hyeontae/venv2/lib/python3.5/site-packages/torch/nn/modules/rnn.py:46: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n",
      "2019-03-28 01:11:19,402 INFO   Optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.0001\n",
      "    weight_decay: 0\n",
      "), Scheduler: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden size is : 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hyeontae/hyeontae/venv2/lib/python3.5/site-packages/torch/nn/functional.py:1320: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    }
   ],
   "source": [
    "for i in hidden_sizes:\n",
    "    hidden_size = i\n",
    "    print(\"hidden size is : %d\" % hidden_size)\n",
    "    seq2seq = None\n",
    "    encoder = EncoderRNN(len(src.vocab), max_len, hidden_size,\n",
    "                         bidirectional=bidirectional, variable_lengths=True)\n",
    "    decoder = DecoderRNN(len(tgt.vocab), max_len, hidden_size * 2 if bidirectional else hidden_size,\n",
    "                         dropout_p=0.2, use_attention=\"Luong\", bidirectional=bidirectional,\n",
    "                         eos_id=tgt.eos_id, sos_id=tgt.sos_id)\n",
    "    seq2seq = Seq2seq(encoder, decoder)\n",
    "    if torch.cuda.is_available():\n",
    "        seq2seq.cuda()\n",
    "\n",
    "    for param in seq2seq.parameters():\n",
    "        param.data.uniform_(-0.08, 0.08)\n",
    "\n",
    "    # train\n",
    "    t = SupervisedTrainer_without_eval(loss=loss, batch_size=32,\n",
    "                                       checkpoint_every=50,\n",
    "                                       print_every=100,\n",
    "                                       hidden_size=hidden_size,\n",
    "                                       path=str(hidden_size))\n",
    "\n",
    "    seq2seq, ave_loss = t.train(seq2seq, train,\n",
    "                                num_epochs=2, dev_data=None,\n",
    "                                optimizer=optimizer,\n",
    "                                teacher_forcing_ratio=0.5)\n",
    "    \n",
    "    depths = list(range(32, 0, -1))\n",
    "    print(depths)\n",
    "    for depth in depths:\n",
    "        dev_path = \"../../../data/bracket_dedup/K100/dev_depth/data_test_depth_\" + str(depth) + \".txt\"\n",
    "        dev = torchtext.data.TabularDataset(\n",
    "              path=dev_path, format='tsv',\n",
    "              fields=[('src', src), ('tgt', tgt)],\n",
    "              filter_pred=len_filter)\n",
    "        _, character_accuracy, _ = evaluator.evaluate(seq2seq, dev)\n",
    "        print(\"Accuracy:%0.4f, Depth:%d\" % (character_accuracy, distance))\n",
    "        check_path = \"../../../log/check_point/bracket_dedup_hidden_size_to_depth/hidden_size_\" + str(i)\n",
    "        with open(check_path, 'a') as f:\n",
    "            f.write(\"Accuracy:%0.4f, Depth:%d\" % (character_accuracy,depth))\n",
    "        \n",
    "        if character_accuracy >= 0.1:\n",
    "            depth_list.append(distance)\n",
    "            break\n",
    "        if distance == 0:\n",
    "            depth_list.append(distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "plt.plot(hidden_sizes, depth_list, LineWidth=3)\n",
    "plt.xlabel('Hidden Size', fontsize=24)\n",
    "plt.ylabel('Depth', fontsize=24)\n",
    "plt.savefig('../../../log/plot/bracket_dedup_hidden_size_to_depth/bracket_dedup_hidden_size_to_depth.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hidden_sizes)\n",
    "print(depth_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
