{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Parameter\n",
    "- Attention = [None, Luong]\n",
    "- Teacher Forcing Ratio = 0.5\n",
    "- Layer = 1\n",
    "- Batch size = 32\n",
    "- Drop out = 0.2\n",
    "- Hidden unit = 50\n",
    "- Epochs = 100\n",
    "- N = 100\n",
    "- Data Length = 100K\n",
    "- Single\n",
    "- Even\n",
    "- Cype = 3\n",
    "- Deduplication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages\n",
    "\n",
    "import useful packages for experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hyeontae/hyeontae/venv2/lib/python3.5/site-packages/torch/nn/_reduction.py:49: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/home/hyeontae/hyeontae/venv2/lib/python3.5/site-packages/torch/nn/_reduction.py:49: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import argparse\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import torchtext\n",
    "\n",
    "sys.path.append(os.path.dirname(os.path.abspath(os.path.dirname(os.path.abspath(os.path.dirname(os.path.abspath(os.path.dirname('__file__'))))))))\n",
    "\n",
    "from trainer.supervised_trainer import SupervisedTrainer\n",
    "from models.encoderRNN import EncoderRNN\n",
    "from models.decoderRNN import DecoderRNN\n",
    "from models.seq2seq import Seq2seq\n",
    "from loss.loss import Perplexity\n",
    "from optim.optim import Optimizer\n",
    "from dataset import fields\n",
    "from evaluator.predictor import Predictor\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Log format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_level = 'info'\n",
    "LOG_FORMAT = '%(asctime)s %(levelname)-6s %(message)s'\n",
    "logging.basicConfig(format=LOG_FORMAT, level=getattr(logging, log_level.upper()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "character_accuracy = []\n",
    "sentence_accuracy = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hyeontae/hyeontae/venv2/lib/python3.5/site-packages/torch/nn/_reduction.py:49: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "train_path = \"../../../data/palindrome_dedup/K100_even_single_Ctype3/data_train.txt\"\n",
    "dev_path = \"../../../data/palindrome_dedup/K100_even_single_Ctype3/data_test.txt\"\n",
    "\n",
    "src = fields.SourceField()\n",
    "tgt = fields.TargetField()\n",
    "max_len = 104\n",
    "def len_filter(example):\n",
    "    return len(example.src) <= max_len and len(example.tgt) <= max_len\n",
    "train = torchtext.data.TabularDataset(\n",
    "    path=train_path, format='tsv',\n",
    "    fields=[('src', src), ('tgt', tgt)],\n",
    "    filter_pred=len_filter\n",
    ")\n",
    "dev = torchtext.data.TabularDataset(\n",
    "    path=dev_path, format='tsv',\n",
    "    fields=[('src', src), ('tgt', tgt)],\n",
    "    filter_pred=len_filter\n",
    ")\n",
    "src.build_vocab(train)\n",
    "tgt.build_vocab(train)\n",
    "input_vocab = src.vocab\n",
    "output_vocab = tgt.vocab\n",
    "\n",
    "weight = torch.ones(len(tgt.vocab))\n",
    "pad = tgt.vocab.stoi[tgt.pad_token]\n",
    "loss = Perplexity(weight, pad)\n",
    "if torch.cuda.is_available():\n",
    "    loss.cuda()\n",
    "    \n",
    "optimizer = \"Adam\"\n",
    "hidden_size = 50\n",
    "bidirectional = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hyeontae/hyeontae/venv2/lib/python3.5/site-packages/torch/nn/modules/rnn.py:46: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n",
      "2019-04-02 00:20:39,339 INFO   Optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.001\n",
      "    weight_decay: 0\n",
      "), Scheduler: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None Att\n"
     ]
    }
   ],
   "source": [
    "print(\"None Att\")\n",
    "\n",
    "seq2seq = None\n",
    "encoder = EncoderRNN(len(src.vocab), max_len, hidden_size,\n",
    "                    bidirectional=bidirectional, variable_lengths=True)\n",
    "decoder = DecoderRNN(len(tgt.vocab), max_len, hidden_size * 2 if bidirectional else hidden_size,\n",
    "                     dropout_p=0.2, use_attention=None, bidirectional=bidirectional,\n",
    "                     eos_id=tgt.eos_id, sos_id=tgt.sos_id)\n",
    "seq2seq = Seq2seq(encoder, decoder)\n",
    "if torch.cuda.is_available():\n",
    "    seq2seq.cuda()\n",
    "\n",
    "for param in seq2seq.parameters():\n",
    "    param.data.uniform_(-0.08, 0.08)\n",
    "\n",
    "# train\n",
    "t = SupervisedTrainer(loss=loss, batch_size=32,\n",
    "                      checkpoint_every=50,\n",
    "                      print_every=100,\n",
    "                      hidden_size=hidden_size,\n",
    "                      path=\"palindrome_dedup_K100_even_single_Ctype3_parameter/None_att\")\n",
    "\n",
    "seq2seq, ave_loss, character_accuracy_list, sentence_accuracy_list = t.train(seq2seq, train,\n",
    "                                                                             num_epochs=100, dev_data=dev,\n",
    "                                                                             optimizer=optimizer,\n",
    "                                                                             teacher_forcing_ratio=0.5)\n",
    "\n",
    "character_accuracy.append(character_accuracy_list)\n",
    "sentence_accuracy.append(sentence_accuracy_list)\n",
    "\n",
    "torch.save(seq2seq.state_dict(), '../../../log/pth/palindrome_dedup_K100_even_single_Ctype3_parameter_no_att_model_save.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Luong Att\")\n",
    "\n",
    "seq2seq = None\n",
    "encoder = EncoderRNN(len(src.vocab), max_len, hidden_size,\n",
    "                    bidirectional=bidirectional, variable_lengths=True)\n",
    "decoder = DecoderRNN(len(tgt.vocab), max_len, hidden_size * 2 if bidirectional else hidden_size,\n",
    "                     dropout_p=0.2, use_attention=\"Luong\", bidirectional=bidirectional,\n",
    "                     eos_id=tgt.eos_id, sos_id=tgt.sos_id)\n",
    "seq2seq = Seq2seq(encoder, decoder)\n",
    "if torch.cuda.is_available():\n",
    "    seq2seq.cuda()\n",
    "\n",
    "for param in seq2seq.parameters():\n",
    "    param.data.uniform_(-0.08, 0.08)\n",
    "\n",
    "# train\n",
    "t = SupervisedTrainer(loss=loss, batch_size=32,\n",
    "                      checkpoint_every=50,\n",
    "                      print_every=100,\n",
    "                      hidden_size=hidden_size,\n",
    "                      path=\"palindrome_dedup_K100_even_single_Ctype3_parameter/Luong_att\")\n",
    "\n",
    "seq2seq, ave_loss, character_accuracy_list, sentence_accuracy_list = t.train(seq2seq, train,\n",
    "                                                                             num_epochs=100, dev_data=dev,\n",
    "                                                                             optimizer=optimizer,\n",
    "                                                                             teacher_forcing_ratio=0.5)\n",
    "\n",
    "character_accuracy.append(character_accuracy_list)\n",
    "sentence_accuracy.append(sentence_accuracy_list)\n",
    "\n",
    "torch.save(seq2seq.state_dict(), '../../../log/pth/palindrome_dedup_K100_even_single_Ctype3_parameter_Luong_att_model_save.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "epochs = list(range(1, 101, 1))\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.plot(epochs[::3], character_accuracy[0][::3], '--', LineWidth=3, label=\"None Att\")\n",
    "plt.plot(epochs[::3], character_accuracy[1][::3], '-o', LineWidth=3, label=\"Luong Att\")\n",
    "plt.legend(loc=\"best\", fontsize=12)\n",
    "plt.xlabel('Epoch', fontsize=24)\n",
    "plt.ylabel('Character Accuracy', fontsize=24)\n",
    "plt.ylim([0, 1])\n",
    "plt.title('palindrome Ctype3', fontsize=35, fontweight=560)\n",
    "plt.savefig('../../../log/plot/palindrome_dedup_K100_even_single_Ctype3_parameter/epoch_to_character_accuracy.png')\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.plot(epochs[::3], sentence_accuracy[0][::3], '--', LineWidth=3, label=\"None Att\")\n",
    "plt.plot(epochs[::3], sentence_accuracy[1][::3], '-o', LineWidth=3, label=\"Luong Att\")\n",
    "plt.legend(loc=\"best\", fontsize=12)\n",
    "plt.xlabel('Epoch', fontsize=24)\n",
    "plt.ylabel('Sentence Accuracy', fontsize=24)\n",
    "plt.ylim([0, 1])\n",
    "plt.title('palindrome Ctype3', fontsize=35, fontweight=560)\n",
    "plt.savefig('../../../log/plot/palindrome_dedup_K100_even_single_Ctype3_parameter/epoch_to_sentence_accuracy.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(character_accuracy[0])\n",
    "print(character_accuracy[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(sentence_accuracy[0])\n",
    "print(sentence_accuracy[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
