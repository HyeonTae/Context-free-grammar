{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Parameter\n",
    "- Attention = True\n",
    "- Teacher Forcing Ratio = 0.5\n",
    "- Layer = 1\n",
    "- Batch size = 32\n",
    "- Learning rate = 0.001\n",
    "- Hidden unit = 200\n",
    "- Epochs = 100\n",
    "- N = 100\n",
    "- Data Length = 100K\n",
    "- Data = [single_Ctype4_error_rate]\n",
    "- Deduplication\n",
    "- Random split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages\n",
    "\n",
    "import useful packages for experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hyeontae/hyeontae/venv1/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/home/hyeontae/hyeontae/venv1/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import argparse\n",
    "import logging\n",
    "import sys\n",
    "import json\n",
    "\n",
    "import torch\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import torchtext\n",
    "\n",
    "os.chdir(os.path.dirname(os.path.abspath(os.path.dirname(os.path.abspath(os.path.dirname(os.path.abspath(os.path.dirname('__file__'))))))))\n",
    "\n",
    "from models.trainer import Trainer\n",
    "from models.seq2seq import Seq2seq\n",
    "from loss.loss import Perplexity\n",
    "from dataset import fields\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Log format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_level = 'info'\n",
    "LOG_FORMAT = '%(asctime)s %(levelname)-6s %(message)s'\n",
    "logging.basicConfig(format=LOG_FORMAT, level=getattr(logging, log_level.upper()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "character_accuracy = []\n",
    "sentence_accuracy = []\n",
    "f1_score = []\n",
    "rnnis = [\"lstm\", \"gru\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rnn : lstm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hyeontae/hyeontae/venv1/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "2019-08-19 02:19:47,478 INFO   Optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.001\n",
      "    weight_decay: 0\n",
      "), Scheduler: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_path : data/palindrome_rand/correction_single_Ctype4_error_rate_5/data_train.txt\n",
      "Dev_path = data/palindrome_rand/correction_single_Ctype4_error_rate_5/data_test.txt\n",
      "{\n",
      "    \"max_len\": 104,\n",
      "    \"embedding_size\": 5,\n",
      "    \"hidden_size\": 200,\n",
      "    \"input_dropout_p\": 0,\n",
      "    \"dropout_p\": 0,\n",
      "    \"n_layers\": 1,\n",
      "    \"bidirectional\": false,\n",
      "    \"rnn_cell\": \"lstm\",\n",
      "    \"variable_lengths\": false,\n",
      "    \"embedding\": null,\n",
      "    \"update_embedding\": true,\n",
      "    \"get_context_vector\": false,\n",
      "    \"use_attention\": true,\n",
      "    \"attn_layers\": 1,\n",
      "    \"hard_attn\": true,\n",
      "    \"position_embedding\": null\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hyeontae/hyeontae/venv1/lib/python3.6/site-packages/torch/nn/functional.py:1374: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "2019-08-19 02:23:59,072 INFO   Finished epoch 1: Train loss: 1.6065, Dev loss: 1.3909, Accuracy(character): 0.9087, Accuracy(sentence): 0.0876, F1 Score: 0.0000\n",
      "2019-08-19 02:27:53,702 INFO   Finished epoch 2: Train loss: 1.3463, Dev loss: 1.3216, Accuracy(character): 0.9337, Accuracy(sentence): 0.3233, F1 Score: 0.4546\n",
      "2019-08-19 02:31:45,347 INFO   Finished epoch 3: Train loss: 1.3789, Dev loss: 1.2320, Accuracy(character): 0.9561, Accuracy(sentence): 0.3198, F1 Score: 0.6378\n",
      "2019-08-19 02:35:36,302 INFO   Finished epoch 4: Train loss: 1.4047, Dev loss: 1.0403, Accuracy(character): 0.9907, Accuracy(sentence): 0.8200, F1 Score: 0.9215\n",
      "2019-08-19 02:39:28,010 INFO   Finished epoch 5: Train loss: 1.1513, Dev loss: 1.0305, Accuracy(character): 0.9928, Accuracy(sentence): 0.8250, F1 Score: 0.9402\n"
     ]
    }
   ],
   "source": [
    "for rnn in rnnis:\n",
    "    print(\"rnn : %s\" % rnn)\n",
    "    train_path = \"data/palindrome_rand/correction_single_Ctype4_error_rate_5/data_train.txt\"\n",
    "    dev_path = \"data/palindrome_rand/correction_single_Ctype4_error_rate_5/data_test.txt\"\n",
    "    config_path = \"models/config.json\"\n",
    "    max_len = 104\n",
    "    src = fields.SourceField()\n",
    "    tgt = fields.TargetField()\n",
    "    def len_filter(example):\n",
    "        return len(example.src) <= max_len and len(example.tgt) <= max_len\n",
    "    train = torchtext.data.TabularDataset(\n",
    "        path=train_path, format='tsv',\n",
    "        fields=[('src', src), ('tgt', tgt)],\n",
    "        filter_pred=len_filter\n",
    "    )\n",
    "    dev = torchtext.data.TabularDataset(\n",
    "        path=dev_path, format='tsv',\n",
    "        fields=[('src', src), ('tgt', tgt)],\n",
    "        filter_pred=len_filter\n",
    "    )\n",
    "    src.build_vocab(train)\n",
    "    tgt.build_vocab(train)\n",
    "    input_vocab = src.vocab\n",
    "    output_vocab = tgt.vocab\n",
    "\n",
    "    weight = torch.ones(len(tgt.vocab))\n",
    "    pad = tgt.vocab.stoi[tgt.pad_token]\n",
    "    loss = Perplexity(weight, pad)\n",
    "    if torch.cuda.is_available():\n",
    "        loss.cuda()\n",
    "        \n",
    "    '''\n",
    "    {\n",
    "        \"max_len\": 102,\n",
    "        \"embedding_size\": 5,\n",
    "        \"hidden_size\": 200,\n",
    "        \"input_dropout_p\": 0,\n",
    "        \"dropout_p\": 0,\n",
    "        \"n_layers\": 1,\n",
    "        \"bidirectional\": false,\n",
    "        \"rnn_cell\": \"lstm\",\n",
    "        \"variable_lengths\": false,\n",
    "        \"embedding\": null,\n",
    "        \"update_embedding\": true,\n",
    "        \"get_context_vector\": false,\n",
    "        \"use_attention\": true,\n",
    "        \"attn_layers\": 1,\n",
    "        \"hard_attn\": false,\n",
    "        \"position_embedding\": null\n",
    "    }\n",
    "\n",
    "    '''\n",
    "\n",
    "    optimizer = \"Adam\"\n",
    "    seq2seq = None\n",
    "    config_json = open(config_path).read()\n",
    "    config = json.loads(config_json)\n",
    "    config[\"max_len\"] = max_len\n",
    "    config[\"rnn_cell\"] = rnn\n",
    "    config[\"hard_attn\"] = True\n",
    "    config[\"position_embedding\"] = None\n",
    "    \n",
    "    print(\"Train_path : %s\" % train_path)\n",
    "    print(\"Dev_path = %s\" % dev_path)\n",
    "    print(json.dumps(config, indent=4))\n",
    "    seq2seq = Seq2seq(config, len(src.vocab), len(tgt.vocab), tgt.sos_id, tgt.eos_id)\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        seq2seq.cuda()\n",
    "\n",
    "    for param in seq2seq.parameters():\n",
    "        param.data.uniform_(-0.08, 0.08)\n",
    "\n",
    "    # train\n",
    "    t = Trainer(loss=loss, batch_size=32,\n",
    "                checkpoint_every=50,\n",
    "                print_every=100,\n",
    "                hidden_size=config[\"hidden_size\"],\n",
    "                path=\"palindrome_rand_error_rate_5_hard_attn\",\n",
    "                file_name=config[\"rnn_cell\"])\n",
    "\n",
    "    seq2seq, ave_loss, character_accuracy_list, sentence_accuracy_list, f1_score_list = t.train(seq2seq, train,\n",
    "                                                                             num_epochs=100, dev_data=dev,\n",
    "                                                                             optimizer=optimizer,\n",
    "                                                                             teacher_forcing_ratio=0.5)\n",
    "\n",
    "    character_accuracy.append(character_accuracy_list)\n",
    "    sentence_accuracy.append(sentence_accuracy_list)\n",
    "    f1_score.append(f1_score_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rnn : lstm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-08-19 16:05:20,225 INFO   Optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.001\n",
      "    weight_decay: 0\n",
      "), Scheduler: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_path : data/palindrome_rand/correction_single_Ctype4_error_rate_5/data_train.txt\n",
      "Dev_path = data/palindrome_rand/correction_single_Ctype4_error_rate_5/data_test.txt\n",
      "{\n",
      "    \"max_len\": 104,\n",
      "    \"embedding_size\": 5,\n",
      "    \"hidden_size\": 200,\n",
      "    \"input_dropout_p\": 0,\n",
      "    \"dropout_p\": 0,\n",
      "    \"n_layers\": 1,\n",
      "    \"bidirectional\": false,\n",
      "    \"rnn_cell\": \"lstm\",\n",
      "    \"variable_lengths\": false,\n",
      "    \"embedding\": null,\n",
      "    \"update_embedding\": true,\n",
      "    \"get_context_vector\": false,\n",
      "    \"use_attention\": true,\n",
      "    \"attn_layers\": 1,\n",
      "    \"hard_attn\": true,\n",
      "    \"position_embedding\": \"length\"\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-08-19 16:10:03,046 INFO   Finished epoch 1: Train loss: 1.4710, Dev loss: 1.2688, Accuracy(character): 0.9370, Accuracy(sentence): 0.2812, F1 Score: 0.0562\n",
      "2019-08-19 16:14:23,271 INFO   Finished epoch 2: Train loss: 1.1245, Dev loss: 1.0210, Accuracy(character): 0.9950, Accuracy(sentence): 0.8612, F1 Score: 0.9596\n",
      "2019-08-19 16:18:45,767 INFO   Finished epoch 3: Train loss: 1.0281, Dev loss: 1.0124, Accuracy(character): 0.9959, Accuracy(sentence): 0.8929, F1 Score: 0.9667\n",
      "2019-08-19 16:23:23,459 INFO   Finished epoch 4: Train loss: 1.0380, Dev loss: 1.0015, Accuracy(character): 0.9996, Accuracy(sentence): 0.9870, F1 Score: 0.9967\n",
      "2019-08-19 16:27:56,644 INFO   Finished epoch 5: Train loss: 1.0254, Dev loss: 1.0031, Accuracy(character): 0.9996, Accuracy(sentence): 0.9832, F1 Score: 0.9965\n",
      "2019-08-19 16:32:09,525 INFO   Finished epoch 6: Train loss: 1.0076, Dev loss: 1.0003, Accuracy(character): 0.9999, Accuracy(sentence): 0.9975, F1 Score: 0.9995\n",
      "2019-08-19 16:36:26,317 INFO   Finished epoch 7: Train loss: 1.0094, Dev loss: 1.0002, Accuracy(character): 0.9999, Accuracy(sentence): 0.9977, F1 Score: 0.9995\n",
      "2019-08-19 16:40:43,383 INFO   Finished epoch 8: Train loss: 1.0114, Dev loss: 1.0002, Accuracy(character): 1.0000, Accuracy(sentence): 0.9984, F1 Score: 0.9997\n",
      "2019-08-19 16:44:59,466 INFO   Finished epoch 9: Train loss: 1.0091, Dev loss: 1.0000, Accuracy(character): 1.0000, Accuracy(sentence): 1.0000, F1 Score: 1.0000\n",
      "2019-08-19 16:49:19,834 INFO   Finished epoch 10: Train loss: 1.0927, Dev loss: 1.0000, Accuracy(character): 1.0000, Accuracy(sentence): 0.9999, F1 Score: 1.0000\n",
      "2019-08-19 16:54:07,165 INFO   Finished epoch 11: Train loss: 1.0045, Dev loss: 1.0000, Accuracy(character): 1.0000, Accuracy(sentence): 0.9999, F1 Score: 1.0000\n",
      "2019-08-19 16:58:54,400 INFO   Finished epoch 12: Train loss: 1.0108, Dev loss: 1.0000, Accuracy(character): 1.0000, Accuracy(sentence): 1.0000, F1 Score: 1.0000\n",
      "2019-08-19 17:03:35,871 INFO   Finished epoch 13: Train loss: 1.0000, Dev loss: 1.0001, Accuracy(character): 1.0000, Accuracy(sentence): 0.9992, F1 Score: 0.9998\n",
      "2019-08-19 17:08:24,536 INFO   Finished epoch 14: Train loss: 1.0682, Dev loss: 1.0000, Accuracy(character): 1.0000, Accuracy(sentence): 0.9995, F1 Score: 0.9999\n",
      "2019-08-19 17:13:10,048 INFO   Finished epoch 15: Train loss: 1.0000, Dev loss: 1.0000, Accuracy(character): 1.0000, Accuracy(sentence): 1.0000, F1 Score: 1.0000\n",
      "2019-08-19 17:17:51,063 INFO   Finished epoch 16: Train loss: 1.0000, Dev loss: 1.0000, Accuracy(character): 1.0000, Accuracy(sentence): 1.0000, F1 Score: 1.0000\n",
      "2019-08-19 17:22:32,124 INFO   Finished epoch 17: Train loss: 1.0000, Dev loss: 1.0000, Accuracy(character): 1.0000, Accuracy(sentence): 1.0000, F1 Score: 1.0000\n",
      "2019-08-19 17:27:20,979 INFO   Finished epoch 18: Train loss: 1.0241, Dev loss: 1.0001, Accuracy(character): 1.0000, Accuracy(sentence): 0.9983, F1 Score: 0.9997\n",
      "2019-08-19 17:32:04,462 INFO   Finished epoch 19: Train loss: 1.0000, Dev loss: 1.0000, Accuracy(character): 1.0000, Accuracy(sentence): 1.0000, F1 Score: 1.0000\n",
      "2019-08-19 17:36:51,973 INFO   Finished epoch 20: Train loss: 1.0361, Dev loss: 1.0000, Accuracy(character): 1.0000, Accuracy(sentence): 1.0000, F1 Score: 1.0000\n",
      "2019-08-19 17:41:29,605 INFO   Finished epoch 21: Train loss: 1.0000, Dev loss: 1.0000, Accuracy(character): 1.0000, Accuracy(sentence): 1.0000, F1 Score: 1.0000\n",
      "2019-08-19 17:46:10,960 INFO   Finished epoch 22: Train loss: 1.0000, Dev loss: 1.0000, Accuracy(character): 1.0000, Accuracy(sentence): 1.0000, F1 Score: 1.0000\n",
      "2019-08-19 17:50:51,906 INFO   Finished epoch 23: Train loss: 1.0000, Dev loss: 1.0000, Accuracy(character): 1.0000, Accuracy(sentence): 1.0000, F1 Score: 1.0000\n",
      "2019-08-19 17:55:31,404 INFO   Finished epoch 24: Train loss: 1.0071, Dev loss: 1.0000, Accuracy(character): 1.0000, Accuracy(sentence): 1.0000, F1 Score: 1.0000\n",
      "2019-08-19 17:59:56,174 INFO   Finished epoch 25: Train loss: 1.0000, Dev loss: 1.0000, Accuracy(character): 1.0000, Accuracy(sentence): 1.0000, F1 Score: 1.0000\n",
      "2019-08-19 18:04:36,880 INFO   Finished epoch 26: Train loss: 1.0303, Dev loss: 1.0108, Accuracy(character): 0.9986, Accuracy(sentence): 0.9570, F1 Score: 0.9891\n",
      "2019-08-19 18:09:07,033 INFO   Finished epoch 27: Train loss: 1.0011, Dev loss: 1.0000, Accuracy(character): 1.0000, Accuracy(sentence): 0.9999, F1 Score: 1.0000\n",
      "2019-08-19 18:13:14,223 INFO   Finished epoch 28: Train loss: 1.0000, Dev loss: 1.0000, Accuracy(character): 1.0000, Accuracy(sentence): 0.9999, F1 Score: 1.0000\n",
      "2019-08-19 18:17:46,240 INFO   Finished epoch 29: Train loss: 1.0000, Dev loss: 1.0000, Accuracy(character): 1.0000, Accuracy(sentence): 0.9999, F1 Score: 1.0000\n",
      "2019-08-19 18:22:22,233 INFO   Finished epoch 30: Train loss: 1.0000, Dev loss: 1.0000, Accuracy(character): 1.0000, Accuracy(sentence): 0.9999, F1 Score: 1.0000\n",
      "2019-08-19 18:26:59,592 INFO   Finished epoch 31: Train loss: 1.0390, Dev loss: 1.0077, Accuracy(character): 0.9980, Accuracy(sentence): 0.9392, F1 Score: 0.9839\n",
      "2019-08-19 18:31:43,616 INFO   Finished epoch 32: Train loss: 1.0003, Dev loss: 1.0000, Accuracy(character): 1.0000, Accuracy(sentence): 1.0000, F1 Score: 1.0000\n",
      "2019-08-19 18:36:36,546 INFO   Finished epoch 33: Train loss: 1.0001, Dev loss: 1.0000, Accuracy(character): 1.0000, Accuracy(sentence): 1.0000, F1 Score: 1.0000\n",
      "2019-08-19 18:41:20,498 INFO   Finished epoch 34: Train loss: 1.0002, Dev loss: 1.0011, Accuracy(character): 0.9999, Accuracy(sentence): 0.9984, F1 Score: 0.9990\n",
      "2019-08-19 18:45:56,002 INFO   Finished epoch 35: Train loss: 1.0009, Dev loss: 1.0000, Accuracy(character): 1.0000, Accuracy(sentence): 1.0000, F1 Score: 1.0000\n",
      "2019-08-19 18:50:30,373 INFO   Finished epoch 36: Train loss: 1.0016, Dev loss: 1.0034, Accuracy(character): 0.9995, Accuracy(sentence): 0.9821, F1 Score: 0.9964\n",
      "2019-08-19 18:55:15,711 INFO   Finished epoch 37: Train loss: 1.0054, Dev loss: 1.0000, Accuracy(character): 1.0000, Accuracy(sentence): 1.0000, F1 Score: 1.0000\n",
      "2019-08-19 19:00:08,770 INFO   Finished epoch 38: Train loss: 1.0002, Dev loss: 1.0007, Accuracy(character): 0.9999, Accuracy(sentence): 0.9941, F1 Score: 0.9989\n",
      "2019-08-19 19:04:44,464 INFO   Finished epoch 39: Train loss: 1.0004, Dev loss: 1.0000, Accuracy(character): 1.0000, Accuracy(sentence): 1.0000, F1 Score: 1.0000\n",
      "2019-08-19 19:09:24,354 INFO   Finished epoch 40: Train loss: 1.0031, Dev loss: 1.0000, Accuracy(character): 1.0000, Accuracy(sentence): 0.9998, F1 Score: 1.0000\n",
      "2019-08-19 19:13:47,246 INFO   Finished epoch 41: Train loss: 1.0031, Dev loss: 1.0000, Accuracy(character): 1.0000, Accuracy(sentence): 0.9997, F1 Score: 0.9999\n",
      "2019-08-19 19:18:27,059 INFO   Finished epoch 42: Train loss: 1.0049, Dev loss: 1.0000, Accuracy(character): 1.0000, Accuracy(sentence): 0.9998, F1 Score: 1.0000\n",
      "2019-08-19 19:23:13,664 INFO   Finished epoch 43: Train loss: 1.0004, Dev loss: 1.0001, Accuracy(character): 1.0000, Accuracy(sentence): 0.9993, F1 Score: 0.9999\n",
      "2019-08-19 19:27:46,115 INFO   Finished epoch 44: Train loss: 1.0002, Dev loss: 1.0005, Accuracy(character): 0.9999, Accuracy(sentence): 0.9959, F1 Score: 0.9992\n",
      "2019-08-19 19:32:21,529 INFO   Finished epoch 45: Train loss: 1.0005, Dev loss: 1.0002, Accuracy(character): 1.0000, Accuracy(sentence): 0.9991, F1 Score: 0.9998\n",
      "2019-08-19 19:36:56,003 INFO   Finished epoch 46: Train loss: 1.0003, Dev loss: 1.0001, Accuracy(character): 1.0000, Accuracy(sentence): 1.0000, F1 Score: 1.0000\n",
      "2019-08-19 19:41:33,540 INFO   Finished epoch 47: Train loss: 1.0003, Dev loss: 1.0056, Accuracy(character): 0.9992, Accuracy(sentence): 0.9677, F1 Score: 0.9935\n",
      "2019-08-19 19:46:07,921 INFO   Finished epoch 48: Train loss: 1.0006, Dev loss: 1.0006, Accuracy(character): 0.9999, Accuracy(sentence): 0.9963, F1 Score: 0.9993\n",
      "2019-08-19 19:50:30,053 INFO   Finished epoch 49: Train loss: 1.0385, Dev loss: 1.0003, Accuracy(character): 1.0000, Accuracy(sentence): 0.9988, F1 Score: 0.9998\n",
      "2019-08-19 19:54:42,803 INFO   Finished epoch 50: Train loss: 1.0021, Dev loss: 1.0021, Accuracy(character): 0.9996, Accuracy(sentence): 0.9842, F1 Score: 0.9969\n",
      "2019-08-19 19:58:57,830 INFO   Finished epoch 51: Train loss: 1.0013, Dev loss: 1.0011, Accuracy(character): 0.9998, Accuracy(sentence): 0.9919, F1 Score: 0.9986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-08-19 20:03:23,875 INFO   Finished epoch 52: Train loss: 1.0006, Dev loss: 1.0004, Accuracy(character): 1.0000, Accuracy(sentence): 0.9998, F1 Score: 1.0000\n",
      "2019-08-19 20:07:36,129 INFO   Finished epoch 53: Train loss: 1.0009, Dev loss: 1.0008, Accuracy(character): 0.9999, Accuracy(sentence): 0.9948, F1 Score: 0.9990\n",
      "2019-08-19 20:11:50,256 INFO   Finished epoch 54: Train loss: 1.0006, Dev loss: 1.0001, Accuracy(character): 1.0000, Accuracy(sentence): 0.9997, F1 Score: 0.9999\n",
      "2019-08-19 20:16:31,266 INFO   Finished epoch 55: Train loss: 1.0004, Dev loss: 1.0001, Accuracy(character): 1.0000, Accuracy(sentence): 0.9998, F1 Score: 1.0000\n",
      "2019-08-19 20:21:14,593 INFO   Finished epoch 56: Train loss: 1.0006, Dev loss: 1.0007, Accuracy(character): 0.9999, Accuracy(sentence): 0.9975, F1 Score: 0.9995\n",
      "2019-08-19 20:25:47,344 INFO   Finished epoch 57: Train loss: 1.0007, Dev loss: 1.0003, Accuracy(character): 1.0000, Accuracy(sentence): 0.9999, F1 Score: 1.0000\n",
      "2019-08-19 20:30:23,235 INFO   Finished epoch 58: Train loss: 1.0007, Dev loss: 1.0003, Accuracy(character): 1.0000, Accuracy(sentence): 0.9999, F1 Score: 1.0000\n",
      "2019-08-19 20:35:01,951 INFO   Finished epoch 59: Train loss: 1.0006, Dev loss: 1.0044, Accuracy(character): 0.9993, Accuracy(sentence): 0.9716, F1 Score: 0.9945\n",
      "2019-08-19 20:39:37,802 INFO   Finished epoch 60: Train loss: 1.0005, Dev loss: 1.0001, Accuracy(character): 1.0000, Accuracy(sentence): 0.9998, F1 Score: 1.0000\n",
      "2019-08-19 20:44:10,530 INFO   Finished epoch 61: Train loss: 1.0008, Dev loss: 1.0003, Accuracy(character): 1.0000, Accuracy(sentence): 0.9993, F1 Score: 0.9999\n",
      "2019-08-19 20:48:38,096 INFO   Finished epoch 62: Train loss: 1.0012, Dev loss: 1.0003, Accuracy(character): 1.0000, Accuracy(sentence): 0.9996, F1 Score: 0.9999\n",
      "2019-08-19 20:53:18,701 INFO   Finished epoch 63: Train loss: 1.0006, Dev loss: 1.0013, Accuracy(character): 0.9998, Accuracy(sentence): 0.9908, F1 Score: 0.9983\n",
      "2019-08-19 20:57:58,433 INFO   Finished epoch 64: Train loss: 1.0012, Dev loss: 1.0004, Accuracy(character): 1.0000, Accuracy(sentence): 0.9998, F1 Score: 1.0000\n",
      "2019-08-19 21:02:30,780 INFO   Finished epoch 65: Train loss: 1.0008, Dev loss: 1.0002, Accuracy(character): 1.0000, Accuracy(sentence): 0.9993, F1 Score: 0.9999\n",
      "2019-08-19 21:07:02,052 INFO   Finished epoch 66: Train loss: 1.0005, Dev loss: 1.0008, Accuracy(character): 0.9999, Accuracy(sentence): 0.9960, F1 Score: 0.9995\n",
      "2019-08-19 21:11:38,315 INFO   Finished epoch 67: Train loss: 1.0006, Dev loss: 1.0025, Accuracy(character): 0.9996, Accuracy(sentence): 0.9842, F1 Score: 0.9975\n",
      "2019-08-19 21:16:15,768 INFO   Finished epoch 68: Train loss: 1.0008, Dev loss: 1.0004, Accuracy(character): 1.0000, Accuracy(sentence): 0.9997, F1 Score: 1.0000\n",
      "2019-08-19 21:20:59,678 INFO   Finished epoch 69: Train loss: 1.0010, Dev loss: 1.0011, Accuracy(character): 0.9998, Accuracy(sentence): 0.9918, F1 Score: 0.9984\n",
      "2019-08-19 21:25:44,733 INFO   Finished epoch 70: Train loss: 1.0005, Dev loss: 1.0005, Accuracy(character): 1.0000, Accuracy(sentence): 0.9998, F1 Score: 1.0000\n",
      "2019-08-19 21:30:29,115 INFO   Finished epoch 71: Train loss: 1.0007, Dev loss: 1.0004, Accuracy(character): 1.0000, Accuracy(sentence): 0.9998, F1 Score: 1.0000\n"
     ]
    }
   ],
   "source": [
    "for rnn in rnnis:\n",
    "    print(\"rnn : %s\" % rnn)\n",
    "    train_path = \"data/palindrome_rand/correction_single_Ctype4_error_rate_5/data_train.txt\"\n",
    "    dev_path = \"data/palindrome_rand/correction_single_Ctype4_error_rate_5/data_test.txt\"\n",
    "    config_path = \"models/config.json\"\n",
    "    max_len = 104\n",
    "    src = fields.SourceField()\n",
    "    tgt = fields.TargetField()\n",
    "    def len_filter(example):\n",
    "        return len(example.src) <= max_len and len(example.tgt) <= max_len\n",
    "    train = torchtext.data.TabularDataset(\n",
    "        path=train_path, format='tsv',\n",
    "        fields=[('src', src), ('tgt', tgt)],\n",
    "        filter_pred=len_filter\n",
    "    )\n",
    "    dev = torchtext.data.TabularDataset(\n",
    "        path=dev_path, format='tsv',\n",
    "        fields=[('src', src), ('tgt', tgt)],\n",
    "        filter_pred=len_filter\n",
    "    )\n",
    "    src.build_vocab(train)\n",
    "    tgt.build_vocab(train)\n",
    "    input_vocab = src.vocab\n",
    "    output_vocab = tgt.vocab\n",
    "\n",
    "    weight = torch.ones(len(tgt.vocab))\n",
    "    pad = tgt.vocab.stoi[tgt.pad_token]\n",
    "    loss = Perplexity(weight, pad)\n",
    "    if torch.cuda.is_available():\n",
    "        loss.cuda()\n",
    "        \n",
    "    '''\n",
    "    {\n",
    "        \"max_len\": 102,\n",
    "        \"embedding_size\": 5,\n",
    "        \"hidden_size\": 200,\n",
    "        \"input_dropout_p\": 0,\n",
    "        \"dropout_p\": 0,\n",
    "        \"n_layers\": 1,\n",
    "        \"bidirectional\": false,\n",
    "        \"rnn_cell\": \"lstm\",\n",
    "        \"variable_lengths\": false,\n",
    "        \"embedding\": null,\n",
    "        \"update_embedding\": true,\n",
    "        \"get_context_vector\": false,\n",
    "        \"use_attention\": true,\n",
    "        \"attn_layers\": 1,\n",
    "        \"hard_attn\": false,\n",
    "        \"position_embedding\": null\n",
    "    }\n",
    "\n",
    "    '''\n",
    "\n",
    "    optimizer = \"Adam\"\n",
    "    seq2seq = None\n",
    "    config_json = open(config_path).read()\n",
    "    config = json.loads(config_json)\n",
    "    config[\"max_len\"] = max_len\n",
    "    config[\"rnn_cell\"] = rnn\n",
    "    config[\"hard_attn\"] = True\n",
    "    config[\"position_embedding\"] = \"length\"\n",
    "    \n",
    "    print(\"Train_path : %s\" % train_path)\n",
    "    print(\"Dev_path = %s\" % dev_path)\n",
    "    print(json.dumps(config, indent=4))\n",
    "    seq2seq = Seq2seq(config, len(src.vocab), len(tgt.vocab), tgt.sos_id, tgt.eos_id)\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        seq2seq.cuda()\n",
    "\n",
    "    for param in seq2seq.parameters():\n",
    "        param.data.uniform_(-0.08, 0.08)\n",
    "\n",
    "    # train\n",
    "    t = Trainer(loss=loss, batch_size=32,\n",
    "                checkpoint_every=50,\n",
    "                print_every=100,\n",
    "                hidden_size=config[\"hidden_size\"],\n",
    "                path=\"palindrome_rand_error_rate_5_hard_attn\",\n",
    "                file_name=config[\"rnn_cell\"] + \"_lenemb\")\n",
    "\n",
    "    seq2seq, ave_loss, character_accuracy_list, sentence_accuracy_list, f1_score_list = t.train(seq2seq, train,\n",
    "                                                                             num_epochs=100, dev_data=dev,\n",
    "                                                                             optimizer=optimizer,\n",
    "                                                                             teacher_forcing_ratio=0.5)\n",
    "\n",
    "    character_accuracy.append(character_accuracy_list)\n",
    "    sentence_accuracy.append(sentence_accuracy_list)\n",
    "    f1_score.append(f1_score_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = list(range(1, 101, 1))\n",
    "plt.figure(figsize=(15,7))\n",
    "plt.plot(epochs[::3], sentence_accuracy[0][::3], '-', LineWidth=3, label=\"LSTM HardAttn\")\n",
    "plt.plot(epochs[::3], sentence_accuracy[1][::3], '-x', LineWidth=3, label=\"GRU HardAttn\")\n",
    "plt.plot(epochs[::3], sentence_accuracy[2][::3], '--', LineWidth=3, label=\"LSTM HardAttn Lenemb\")\n",
    "plt.plot(epochs[::3], sentence_accuracy[3][::3], '-x', LineWidth=3, label=\"GRU HardAttn Lenemb\")\n",
    "\n",
    "plt.legend(loc=\"best\", fontsize=12)\n",
    "plt.xlabel('Epoch', fontsize=24)\n",
    "plt.ylabel('Sentence Accuracy', fontsize=24)\n",
    "plt.ylim([0, 1])\n",
    "#plt.savefig('../../../log/plot/gru_palindrome_rand_correction_ctype4_lenemb_add_order_encoder_decoder/ctype_to_sentence_accuracy.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,7))\n",
    "plt.plot(epochs[::3], f1_score[0][::3], '-', LineWidth=3, label=\"LSTM HardAttn\")\n",
    "plt.plot(epochs[::3], f1_score[1][::3], '-x', LineWidth=3, label=\"GRU HardAttn\")\n",
    "plt.plot(epochs[::3], f1_score[2][::3], '--', LineWidth=3, label=\"LSTM HardAttn Lenemb\")\n",
    "plt.plot(epochs[::3], f1_score[3][::3], '-x', LineWidth=3, label=\"GRU HardAttn Lenemb\")\n",
    "plt.legend(loc=\"best\", fontsize=12)\n",
    "plt.xlabel('Epoch', fontsize=24)\n",
    "plt.ylabel('F1 Score', fontsize=24)\n",
    "plt.ylim([0, 1])\n",
    "#plt.savefig('../../../log/plot/gru_palindrome_rand_correction_ctype4_lenemb_add_order_encoder_decoder/ctype_to_f1_score.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_rate_list = []\n",
    "for i in range(len(character_accuracy)):\n",
    "    error_rate = []\n",
    "    for j in character_accuracy[i]:\n",
    "        error_rate.append(1 - j)\n",
    "    error_rate_list.append(error_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = list(range(1, 101, 1))\n",
    "plt.figure(figsize=(15,7))\n",
    "plt.plot(epochs[::3], error_rate_list[0][::3], '-', LineWidth=3, label=\"LSTM HardAttn\")\n",
    "plt.plot(epochs[::3], error_rate_list[1][::3], '-x', LineWidth=3, label=\"GRU HardAttn\")\n",
    "plt.plot(epochs[::3], error_rate_list[2][::3], '--', LineWidth=3, label=\"LSTM HardAttn Lenemb\")\n",
    "plt.plot(epochs[::3], error_rate_list[3][::3], '-x', LineWidth=3, label=\"GRU HardAttn Lenemb\")\n",
    "plt.legend(loc=\"best\", fontsize=12)\n",
    "plt.xlabel('Epoch', fontsize=24)\n",
    "plt.ylabel('Error Rate', fontsize=24)\n",
    "plt.yscale('log')\n",
    "#plt.ylim([0, 1])\n",
    "#plt.savefig('../../../log/plot/gru_palindrome_rand_correction_ctype4_lenemb_add_order_encoder_decoder/ctype_to_error_rate.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(len(character_accuracy))\n",
    "for i in character_accuracy:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(len(sentence_accuracy))\n",
    "for i in sentence_accuracy:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(len(f1_score))\n",
    "for i in f1_score:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(error_rate_list))\n",
    "for i in error_rate_list:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
