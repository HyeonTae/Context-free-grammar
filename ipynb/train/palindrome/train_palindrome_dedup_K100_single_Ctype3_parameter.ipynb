{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Parameter\n",
    "- Attention = [None, Luong]\n",
    "- Teacher Forcing Ratio = 0.5\n",
    "- Layer = 1\n",
    "- Batch size = 32\n",
    "- Drop out = 0.2\n",
    "- Hidden unit = 50\n",
    "- Epochs = 100\n",
    "- N = 100\n",
    "- Data Length = 100K\n",
    "- Single\n",
    "- Cype = 3\n",
    "- Deduplication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages\n",
    "\n",
    "import useful packages for experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import torchtext\n",
    "\n",
    "sys.path.append(os.path.dirname(os.path.abspath(os.path.dirname(os.path.abspath(os.path.dirname(os.path.abspath(os.path.dirname('__file__'))))))))\n",
    "\n",
    "from trainer.supervised_trainer import SupervisedTrainer\n",
    "from models.encoderRNN import EncoderRNN\n",
    "from models.decoderRNN import DecoderRNN\n",
    "from models.seq2seq import Seq2seq\n",
    "from loss.loss import Perplexity\n",
    "from optim.optim import Optimizer\n",
    "from dataset import fields\n",
    "from evaluator.predictor import Predictor\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Log format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_level = 'info'\n",
    "LOG_FORMAT = '%(asctime)s %(levelname)-6s %(message)s'\n",
    "logging.basicConfig(format=LOG_FORMAT, level=getattr(logging, log_level.upper()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "character_accuracy = []\n",
    "sentence_accuracy = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hyeontae/hyeontae/venv2/lib/python3.5/site-packages/torch/nn/_reduction.py:49: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "train_path = \"../../../data/palindrome_dedup/K100_single_Ctype3/data_train.txt\"\n",
    "dev_path = \"../../../data/palindrome_dedup/K100_single_Ctype3/data_test.txt\"\n",
    "\n",
    "src = fields.SourceField()\n",
    "tgt = fields.TargetField()\n",
    "max_len = 104\n",
    "def len_filter(example):\n",
    "    return len(example.src) <= max_len and len(example.tgt) <= max_len\n",
    "train = torchtext.data.TabularDataset(\n",
    "    path=train_path, format='tsv',\n",
    "    fields=[('src', src), ('tgt', tgt)],\n",
    "    filter_pred=len_filter\n",
    ")\n",
    "dev = torchtext.data.TabularDataset(\n",
    "    path=dev_path, format='tsv',\n",
    "    fields=[('src', src), ('tgt', tgt)],\n",
    "    filter_pred=len_filter\n",
    ")\n",
    "src.build_vocab(train)\n",
    "tgt.build_vocab(train)\n",
    "input_vocab = src.vocab\n",
    "output_vocab = tgt.vocab\n",
    "\n",
    "weight = torch.ones(len(tgt.vocab))\n",
    "pad = tgt.vocab.stoi[tgt.pad_token]\n",
    "loss = Perplexity(weight, pad)\n",
    "if torch.cuda.is_available():\n",
    "    loss.cuda()\n",
    "    \n",
    "optimizer = \"Adam\"\n",
    "hidden_size = 50\n",
    "bidirectional = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hyeontae/hyeontae/venv2/lib/python3.5/site-packages/torch/nn/modules/rnn.py:46: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n",
      "2019-04-04 16:51:23,754 INFO   Optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.001\n",
      "    weight_decay: 0\n",
      "), Scheduler: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Luong Att\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hyeontae/hyeontae/venv2/lib/python3.5/site-packages/torch/nn/functional.py:1320: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "2019-04-04 16:54:42,627 INFO   Finished epoch 1: Train loss: 12.3892, Dev loss: 13.7093, Accuracy(Character): 0.3911, Accuracy(Word): 0.0000\n",
      "2019-04-04 16:57:54,671 INFO   Finished epoch 2: Train loss: 5.3609, Dev loss: 5.5819, Accuracy(Character): 0.5814, Accuracy(Word): 0.0000\n",
      "2019-04-04 17:01:13,471 INFO   Finished epoch 3: Train loss: 4.2627, Dev loss: 4.6622, Accuracy(Character): 0.6283, Accuracy(Word): 0.0000\n",
      "2019-04-04 17:04:27,400 INFO   Finished epoch 4: Train loss: 4.4365, Dev loss: 12.2878, Accuracy(Character): 0.5565, Accuracy(Word): 0.0000\n",
      "2019-04-04 17:07:42,899 INFO   Finished epoch 5: Train loss: 7.8640, Dev loss: 16.9701, Accuracy(Character): 0.5341, Accuracy(Word): 0.0000\n",
      "2019-04-04 17:11:01,413 INFO   Finished epoch 6: Train loss: 8.3854, Dev loss: 18.0085, Accuracy(Character): 0.5226, Accuracy(Word): 0.0000\n",
      "2019-04-04 17:14:51,373 INFO   Finished epoch 7: Train loss: 11.8373, Dev loss: 35.3184, Accuracy(Character): 0.4766, Accuracy(Word): 0.0000\n",
      "2019-04-04 17:18:10,300 INFO   Finished epoch 8: Train loss: 8.2413, Dev loss: 67.8440, Accuracy(Character): 0.4861, Accuracy(Word): 0.0000\n",
      "2019-04-04 17:21:25,352 INFO   Finished epoch 9: Train loss: 9.0230, Dev loss: 47.2444, Accuracy(Character): 0.4868, Accuracy(Word): 0.0000\n",
      "2019-04-04 17:25:16,204 INFO   Finished epoch 10: Train loss: 11.8251, Dev loss: 79.1539, Accuracy(Character): 0.4883, Accuracy(Word): 0.0000\n",
      "2019-04-04 17:29:23,573 INFO   Finished epoch 11: Train loss: 154.1965, Dev loss: 52.5590, Accuracy(Character): 0.4892, Accuracy(Word): 0.0000\n",
      "2019-04-04 17:33:15,542 INFO   Finished epoch 12: Train loss: 11.1801, Dev loss: 106.6702, Accuracy(Character): 0.4871, Accuracy(Word): 0.0000\n",
      "2019-04-04 17:37:45,896 INFO   Finished epoch 13: Train loss: 9.4663, Dev loss: 60.4943, Accuracy(Character): 0.4923, Accuracy(Word): 0.0000\n",
      "2019-04-04 17:41:40,056 INFO   Finished epoch 14: Train loss: 8.1276, Dev loss: 80.7823, Accuracy(Character): 0.4914, Accuracy(Word): 0.0000\n",
      "2019-04-04 17:45:31,381 INFO   Finished epoch 15: Train loss: 9.2818, Dev loss: 78.8833, Accuracy(Character): 0.5017, Accuracy(Word): 0.0000\n",
      "2019-04-04 17:49:18,711 INFO   Finished epoch 16: Train loss: 7.4927, Dev loss: 60.3721, Accuracy(Character): 0.5007, Accuracy(Word): 0.0000\n",
      "2019-04-04 17:53:03,295 INFO   Finished epoch 17: Train loss: 9.8151, Dev loss: 111.8533, Accuracy(Character): 0.4912, Accuracy(Word): 0.0000\n",
      "2019-04-04 17:56:49,688 INFO   Finished epoch 18: Train loss: 8.4572, Dev loss: 146.7494, Accuracy(Character): 0.4803, Accuracy(Word): 0.0000\n",
      "2019-04-04 18:00:36,026 INFO   Finished epoch 19: Train loss: 9.2922, Dev loss: 96.5899, Accuracy(Character): 0.5005, Accuracy(Word): 0.0000\n",
      "2019-04-04 18:04:28,730 INFO   Finished epoch 20: Train loss: 14.0367, Dev loss: 120.0416, Accuracy(Character): 0.4859, Accuracy(Word): 0.0000\n",
      "2019-04-04 18:08:22,217 INFO   Finished epoch 21: Train loss: 11.3019, Dev loss: 101.0888, Accuracy(Character): 0.4949, Accuracy(Word): 0.0000\n",
      "2019-04-04 18:12:18,393 INFO   Finished epoch 22: Train loss: 8.8374, Dev loss: 380.1525, Accuracy(Character): 0.4858, Accuracy(Word): 0.0000\n",
      "2019-04-04 18:16:06,368 INFO   Finished epoch 23: Train loss: 8.2369, Dev loss: 100.2305, Accuracy(Character): 0.4911, Accuracy(Word): 0.0000\n",
      "2019-04-04 18:19:54,368 INFO   Finished epoch 24: Train loss: 8.8807, Dev loss: 119.6058, Accuracy(Character): 0.4916, Accuracy(Word): 0.0000\n",
      "2019-04-04 18:23:39,356 INFO   Finished epoch 25: Train loss: 8.6300, Dev loss: 195.0892, Accuracy(Character): 0.4903, Accuracy(Word): 0.0000\n",
      "2019-04-04 18:27:29,818 INFO   Finished epoch 26: Train loss: 10.0913, Dev loss: 165.8288, Accuracy(Character): 0.4912, Accuracy(Word): 0.0000\n",
      "2019-04-04 18:31:21,392 INFO   Finished epoch 27: Train loss: 10.4530, Dev loss: 307.6743, Accuracy(Character): 0.4858, Accuracy(Word): 0.0000\n",
      "2019-04-04 18:35:15,341 INFO   Finished epoch 28: Train loss: 7.9839, Dev loss: 280.8556, Accuracy(Character): 0.4805, Accuracy(Word): 0.0000\n",
      "2019-04-04 18:39:03,933 INFO   Finished epoch 29: Train loss: 92.8632, Dev loss: 186.6189, Accuracy(Character): 0.4947, Accuracy(Word): 0.0000\n",
      "2019-04-04 18:42:30,720 INFO   Finished epoch 30: Train loss: 10.7011, Dev loss: 125.2930, Accuracy(Character): 0.4911, Accuracy(Word): 0.0000\n",
      "2019-04-04 18:45:39,221 INFO   Finished epoch 31: Train loss: 10.2558, Dev loss: 316.3360, Accuracy(Character): 0.4932, Accuracy(Word): 0.0000\n",
      "2019-04-04 18:48:49,879 INFO   Finished epoch 32: Train loss: 10.2257, Dev loss: 341.6984, Accuracy(Character): 0.5117, Accuracy(Word): 0.0000\n",
      "2019-04-04 18:52:08,559 INFO   Finished epoch 33: Train loss: 7.4538, Dev loss: 142.5568, Accuracy(Character): 0.4923, Accuracy(Word): 0.0000\n",
      "2019-04-04 18:55:24,176 INFO   Finished epoch 34: Train loss: 10.5528, Dev loss: 166.5599, Accuracy(Character): 0.4947, Accuracy(Word): 0.0000\n",
      "2019-04-04 18:58:35,861 INFO   Finished epoch 35: Train loss: 19.5662, Dev loss: 128.3782, Accuracy(Character): 0.4923, Accuracy(Word): 0.0000\n",
      "2019-04-04 19:01:45,745 INFO   Finished epoch 36: Train loss: 14.3037, Dev loss: 188.0841, Accuracy(Character): 0.4929, Accuracy(Word): 0.0000\n",
      "2019-04-04 19:04:56,326 INFO   Finished epoch 37: Train loss: 11.6797, Dev loss: 241.1619, Accuracy(Character): 0.4907, Accuracy(Word): 0.0000\n",
      "2019-04-04 19:08:02,706 INFO   Finished epoch 38: Train loss: 8.8465, Dev loss: 219.2159, Accuracy(Character): 0.4931, Accuracy(Word): 0.0000\n",
      "2019-04-04 19:11:12,961 INFO   Finished epoch 39: Train loss: 47.2908, Dev loss: 259.1170, Accuracy(Character): 0.4929, Accuracy(Word): 0.0000\n",
      "2019-04-04 19:14:20,419 INFO   Finished epoch 40: Train loss: 10.0767, Dev loss: 281.0595, Accuracy(Character): 0.4927, Accuracy(Word): 0.0000\n",
      "2019-04-04 19:17:29,351 INFO   Finished epoch 41: Train loss: 11.2831, Dev loss: 416.3901, Accuracy(Character): 0.4922, Accuracy(Word): 0.0000\n",
      "2019-04-04 19:20:41,147 INFO   Finished epoch 42: Train loss: 13.0950, Dev loss: 446.6721, Accuracy(Character): 0.4875, Accuracy(Word): 0.0000\n",
      "2019-04-04 19:23:55,214 INFO   Finished epoch 43: Train loss: 9.0909, Dev loss: 360.8670, Accuracy(Character): 0.4861, Accuracy(Word): 0.0000\n",
      "2019-04-04 19:27:05,087 INFO   Finished epoch 44: Train loss: 13.5419, Dev loss: 202.6332, Accuracy(Character): 0.4912, Accuracy(Word): 0.0000\n",
      "2019-04-04 19:30:16,317 INFO   Finished epoch 45: Train loss: 8.5562, Dev loss: 400.8311, Accuracy(Character): 0.4925, Accuracy(Word): 0.0000\n",
      "2019-04-04 19:33:26,842 INFO   Finished epoch 46: Train loss: 12.8601, Dev loss: 336.2242, Accuracy(Character): 0.4996, Accuracy(Word): 0.0000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-e061e3d619ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m                                                                              \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdev\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m                                                                              \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                                                                              teacher_forcing_ratio=0.5)\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mcharacter_accuracy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcharacter_accuracy_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/hyeontae/Context-Free_Grammar/trainer/supervised_trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, model, data, num_epochs, resume, dev_data, optimizer, teacher_forcing_ratio)\u001b[0m\n\u001b[1;32m    224\u001b[0m         loss, character_accuracy_list, sentance_accuracy_list = self._train_epoches(data, model, num_epochs,\n\u001b[1;32m    225\u001b[0m                                                                 \u001b[0mstart_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdev_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m                                                                 teacher_forcing_ratio=teacher_forcing_ratio)\n\u001b[0m\u001b[1;32m    227\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcharacter_accuracy_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentance_accuracy_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/hyeontae/Context-Free_Grammar/trainer/supervised_trainer.py\u001b[0m in \u001b[0;36m_train_epoches\u001b[0;34m(self, data, model, n_epochs, start_epoch, start_step, dev_data, teacher_forcing_ratio)\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_loss_avg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdev_data\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m                 \u001b[0mdev_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcharacter_accuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentance_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m                 \u001b[0mlog_msg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\", Dev %s: %.4f, Accuracy(Character): %.4f, Accuracy(Word): %.4f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcharacter_accuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentance_accuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/hyeontae/Context-Free_Grammar/evaluator/evaluator.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, model, data)\u001b[0m\n\u001b[1;32m     38\u001b[0m                 \u001b[0mtarget_variables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'tgt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m                 \u001b[0mdecoder_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_hidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_variables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_lengths\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m                 \u001b[0mcorrect_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m                 \u001b[0;31m# Evaluation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/hyeontae/venv2/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/hyeontae/Context-Free_Grammar/models/seq2seq.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_variable, input_lengths, target_variable, teacher_forcing_ratio)\u001b[0m\n\u001b[1;32m     21\u001b[0m                               \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m                               \u001b[0mfunction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m                               teacher_forcing_ratio=teacher_forcing_ratio)\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/hyeontae/venv2/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/hyeontae/Context-Free_Grammar/models/decoderRNN.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs, encoder_hidden, encoder_outputs, function, teacher_forcing_ratio)\u001b[0m\n\u001b[1;32m    155\u001b[0m                     \u001b[0mdecoder_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_hidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_attn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_step_BahdanauAtt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_hidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m                     \u001b[0mdecoder_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_hidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_attn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_hidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m                 \u001b[0mstep_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m                 \u001b[0msymbols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_attn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/hyeontae/Context-Free_Grammar/models/decoderRNN.py\u001b[0m in \u001b[0;36mforward_step\u001b[0;34m(self, input_var, hidden, encoder_outputs, function)\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0mattn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_attention\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;34m\"Luong\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m             \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mpredicted_softmax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/hyeontae/venv2/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/hyeontae/Context-Free_Grammar/models/attention.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, output, context)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0minput_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;31m# (batch, out_len, dim) * (batch, in_len, dim) -> (batch, out_len, in_len)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mattn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mattn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasked_fill_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'inf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"Luong Att\")\n",
    "\n",
    "seq2seq = None\n",
    "encoder = EncoderRNN(len(src.vocab), max_len, hidden_size,\n",
    "                    bidirectional=bidirectional, variable_lengths=True)\n",
    "decoder = DecoderRNN(len(tgt.vocab), max_len, hidden_size * 2 if bidirectional else hidden_size,\n",
    "                     dropout_p=0.2, use_attention=\"Luong\", bidirectional=bidirectional,\n",
    "                     eos_id=tgt.eos_id, sos_id=tgt.sos_id)\n",
    "seq2seq = Seq2seq(encoder, decoder)\n",
    "if torch.cuda.is_available():\n",
    "    seq2seq.cuda()\n",
    "\n",
    "for param in seq2seq.parameters():\n",
    "    param.data.uniform_(-0.08, 0.08)\n",
    "\n",
    "# train\n",
    "t = SupervisedTrainer(loss=loss, batch_size=32,\n",
    "                      checkpoint_every=50,\n",
    "                      print_every=100,\n",
    "                      hidden_size=hidden_size,\n",
    "                      path=\"palindrome_dedup_K100_single_Ctype3_parameter/Luong_att\")\n",
    "\n",
    "seq2seq, ave_loss, character_accuracy_list, sentence_accuracy_list = t.train(seq2seq, train,\n",
    "                                                                             num_epochs=100, dev_data=dev,\n",
    "                                                                             optimizer=optimizer,\n",
    "                                                                             teacher_forcing_ratio=0.5)\n",
    "\n",
    "character_accuracy.append(character_accuracy_list)\n",
    "sentence_accuracy.append(sentence_accuracy_list)\n",
    "\n",
    "torch.save(seq2seq.state_dict(), '../../../log/pth/palindrome_dedup_K100_single_Ctype3_parameter_Luong_att_model_save.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"None Att\")\n",
    "\n",
    "seq2seq = None\n",
    "encoder = EncoderRNN(len(src.vocab), max_len, hidden_size,\n",
    "                    bidirectional=bidirectional, variable_lengths=True)\n",
    "decoder = DecoderRNN(len(tgt.vocab), max_len, hidden_size * 2 if bidirectional else hidden_size,\n",
    "                     dropout_p=0.2, use_attention=None, bidirectional=bidirectional,\n",
    "                     eos_id=tgt.eos_id, sos_id=tgt.sos_id)\n",
    "seq2seq = Seq2seq(encoder, decoder)\n",
    "if torch.cuda.is_available():\n",
    "    seq2seq.cuda()\n",
    "\n",
    "for param in seq2seq.parameters():\n",
    "    param.data.uniform_(-0.08, 0.08)\n",
    "\n",
    "# train\n",
    "t = SupervisedTrainer(loss=loss, batch_size=32,\n",
    "                      checkpoint_every=50,\n",
    "                      print_every=100,\n",
    "                      hidden_size=hidden_size,\n",
    "                      path=\"palindrome_dedup_K100_single_Ctype3_parameter/None_att\")\n",
    "\n",
    "seq2seq, ave_loss, character_accuracy_list, sentence_accuracy_list = t.train(seq2seq, train,\n",
    "                                                                             num_epochs=100, dev_data=dev,\n",
    "                                                                             optimizer=optimizer,\n",
    "                                                                             teacher_forcing_ratio=0.5)\n",
    "\n",
    "character_accuracy.append(character_accuracy_list)\n",
    "sentence_accuracy.append(sentence_accuracy_list)\n",
    "\n",
    "torch.save(seq2seq.state_dict(), '../../../log/pth/palindrome_dedup_K100_single_Ctype3_parameter_no_att_model_save.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "epochs = list(range(1, 101, 1))\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.plot(epochs[::3], character_accuracy[0][::3], '--', LineWidth=3, label=\"Luong Att\")\n",
    "plt.plot(epochs[::3], character_accuracy[1][::3], '-o', LineWidth=3, label=\"None Att\")\n",
    "plt.legend(loc=\"best\", fontsize=12)\n",
    "plt.xlabel('Epoch', fontsize=24)\n",
    "plt.ylabel('Character Accuracy', fontsize=24)\n",
    "plt.ylim([0, 1])\n",
    "plt.title('palindrome Ctype3', fontsize=35, fontweight=560)\n",
    "plt.savefig('../../../log/plot/palindrome_dedup_K100_single_Ctype3_parameter/epoch_to_character_accuracy.png')\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.plot(epochs[::3], sentence_accuracy[0][::3], '--', LineWidth=3, label=\"Luong Att\")\n",
    "plt.plot(epochs[::3], sentence_accuracy[1][::3], '-o', LineWidth=3, label=\"None Att\")\n",
    "plt.legend(loc=\"best\", fontsize=12)\n",
    "plt.xlabel('Epoch', fontsize=24)\n",
    "plt.ylabel('Sentence Accuracy', fontsize=24)\n",
    "plt.ylim([0, 1])\n",
    "plt.title('palindrome Ctype3', fontsize=35, fontweight=560)\n",
    "plt.savefig('../../../log/plot/palindrome_dedup_K100_single_Ctype3_parameter/epoch_to_sentence_accuracy.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(character_accuracy[0])\n",
    "print(character_accuracy[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(sentence_accuracy[0])\n",
    "print(sentence_accuracy[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
