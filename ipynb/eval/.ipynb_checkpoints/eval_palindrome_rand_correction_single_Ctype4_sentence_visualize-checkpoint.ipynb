{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hyeontae/hyeontae/venv/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/home/hyeontae/hyeontae/venv/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import argparse\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import torchtext\n",
    "\n",
    "sys.path.append(os.path.dirname(os.path.abspath(os.path.dirname(os.path.abspath(os.path.dirname('__file__'))))))\n",
    "\n",
    "from trainer.supervised_trainer import SupervisedTrainer\n",
    "from trainer.supervised_trainer_unmatching import SupervisedTrainer_unmatching\n",
    "from models.encoderRNN import EncoderRNN\n",
    "from models.decoderRNN import DecoderRNN\n",
    "from models.seq2seq import Seq2seq\n",
    "from loss.loss import Perplexity\n",
    "from optim.optim import Optimizer\n",
    "from dataset import fields\n",
    "from evaluator.predictor import Predictor\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from collections import deque\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"../../data/palindrome_rand/correction_single_Ctype4/data_train.txt\"\n",
    "log_path = \"../../log/pth/train_palindrome_rand_correction_ctype4_single_Ctype4_model_save.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG_FORMAT = '%(asctime)s %(name)-12s %(levelname)-8s %(message)s'\n",
    "logging.basicConfig(format=LOG_FORMAT, level=getattr(logging, \"info\".upper()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare dataset\n",
    "src = fields.SourceField()\n",
    "tgt = fields.TargetField()\n",
    "max_len = 104\n",
    "def len_filter(example):\n",
    "    return len(example.src) <= max_len and len(example.tgt) <= max_len\n",
    "train = torchtext.data.TabularDataset(\n",
    "    path=train_path, format='tsv',\n",
    "    fields=[('src', src), ('tgt', tgt)],\n",
    "    filter_pred=len_filter\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "src.build_vocab(train)\n",
    "tgt.build_vocab(train)\n",
    "input_vocab = src.vocab\n",
    "output_vocab = tgt.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hyeontae/hyeontae/venv/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "# Prepare loss\n",
    "weight = torch.ones(len(tgt.vocab))\n",
    "pad = tgt.vocab.stoi[tgt.pad_token]\n",
    "loss = Perplexity(weight, pad)\n",
    "if torch.cuda.is_available():\n",
    "    loss.cuda()\n",
    "\n",
    "seq2seq = None\n",
    "seq2seq_no = None\n",
    "optimizer = \"Adam\"\n",
    "hidden_size = 200\n",
    "bidirectional = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize model Luong att"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hyeontae/hyeontae/venv/lib/python3.6/site-packages/torch/nn/modules/rnn.py:54: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    }
   ],
   "source": [
    "# Initialize model\n",
    "encoder = EncoderRNN(len(src.vocab), max_len, hidden_size, n_layers=1,\n",
    "                    bidirectional=bidirectional, variable_lengths=True)\n",
    "decoder = DecoderRNN(len(tgt.vocab), max_len, hidden_size * 2 if bidirectional else hidden_size,\n",
    "                    dropout_p=0.2, use_attention=\"Luong\", bidirectional=bidirectional, n_layers=1,\n",
    "                    eos_id=tgt.eos_id, sos_id=tgt.sos_id)\n",
    "seq2seq = Seq2seq(encoder, decoder)\n",
    "if torch.cuda.is_available():\n",
    "    seq2seq.cuda()\n",
    "\n",
    "for param in seq2seq.parameters():\n",
    "    param.data.uniform_(-0.08, 0.08)\n",
    "\n",
    "seq2seq.load_state_dict(torch.load(log_path))\n",
    "seq2seq.eval()\n",
    "\n",
    "predictor = Predictor(seq2seq, input_vocab, output_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answer function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_function(data):\n",
    "    results = []\n",
    "    words = data.split(\"#\")\n",
    "    comp = []\n",
    "    for word in words:\n",
    "        result = \"\"\n",
    "        m = int(len(word)/2)\n",
    "        for i in range(0,m):\n",
    "            result += \"0\"\n",
    "            comp.append(word[i])\n",
    "        if len(word)%2 != 0:\n",
    "            result += \"0\"\n",
    "            m += 1\n",
    "        for i in range(m,len(word)):\n",
    "            w = comp.pop()\n",
    "            if word[i] != w:\n",
    "                if w == \"a\":\n",
    "                    result += \"1\"\n",
    "                elif w == \"b\":\n",
    "                    result += \"2\"\n",
    "                elif w == \"c\":\n",
    "                    result += \"3\"\n",
    "                elif w == \"d\":\n",
    "                    result += \"4\"\n",
    "                else:\n",
    "                    result += \"0\"\n",
    "            else:\n",
    "                result += \"0\"\n",
    "                \n",
    "        results.append(result)\n",
    "\n",
    "    return \" \".join(\"0\".join(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_function(x):\n",
    "    \n",
    "    if x > 0:\n",
    "        if x < 0.5:\n",
    "            return 0\n",
    "        else:\n",
    "            return 1\n",
    "    else:\n",
    "        if x > -0.5:\n",
    "            return 0\n",
    "        else:\n",
    "            return -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    encoder_outputs = []\n",
    "    while True:\n",
    "        seq_str = input(\"input : \")\n",
    "        if seq_str == 'q':\n",
    "            break\n",
    "        \n",
    "        seq = \"\".join(seq_str.strip().split())\n",
    "        tgt_seq, tgt_att_list, encoder_output, encoder_context = predictor.predict(seq)\n",
    "        print(\"Answer: \" + answer_function(seq))\n",
    "        print(\"Luong : \" + \" \".join(tgt_seq))\n",
    "        \n",
    "        encoder_outputs.append(encoder_output.tolist().pop())\n",
    "        \n",
    "    encoder_outputs = np.array(encoder_outputs)\n",
    "    #---------Hidden PCA-----------------------------------------------------------------------------------\n",
    "    principalComponents = PCA(n_components=2)\n",
    "    pca = principalComponents.fit_transform(encoder_outputs)\n",
    "        \n",
    "    fig2 = plt.figure(figsize=(8,8))\n",
    "    ax2 = fig2.add_subplot(111)\n",
    "    ax2.set_xlabel('PC1', fontsize = 15)\n",
    "    ax2.set_ylabel('PC2', fontsize = 15)\n",
    "    ax2.set_title('Hidden PCA', fontsize = 20)\n",
    "    for i, j in zip(seq, range(len(pca))):\n",
    "        if i == 'a':\n",
    "            ax2.scatter(pca[j][0], pca[j][1], c='r', label='a')\n",
    "            ax2.annotate(str(j),(pca[j][0], pca[j][1]), color='r')\n",
    "        elif i == 'b':\n",
    "            ax2.scatter(pca[j][0], pca[j][1], c='b', marker='+', label='b')\n",
    "            ax2.annotate(str(j),(pca[j][0], pca[j][1]), color='b')\n",
    "        elif i == 'c':\n",
    "            ax2.scatter(pca[j][0], pca[j][1], c='g', marker='^', label='c')\n",
    "            ax2.annotate(str(j),(pca[j][0], pca[j][1]), color='g')\n",
    "        elif i == 'd':\n",
    "            ax2.scatter(pca[j][0], pca[j][1], c='k', marker='s', label='d')\n",
    "            ax2.annotate(str(j),(pca[j][0], pca[j][1]), color='k')\n",
    "        elif i == '#':\n",
    "            ax2.scatter(pca[j][0], pca[j][1], c='y', marker='*', label='#')\n",
    "            ax2.annotate(str(j),(pca[j][0], pca[j][1]), color='y')\n",
    "    #ax2.legend(bbox_to_anchor=(1, 1))\n",
    "    ax2.grid()\n",
    "    plt.show()\n",
    "        \n",
    "    #---------Hidden t-SNE---------------------------------------------------------------------------------\n",
    "    tsne = TSNE(learning_rate=100)\n",
    "    transformed = tsne.fit_transform(encoder_outputs)\n",
    "    fig111 = plt.figure(figsize=(8,8))\n",
    "    ax111 = fig111.add_subplot(111)\n",
    "        \n",
    "    ax111.set_xlabel('PC1', fontsize = 15)\n",
    "    ax111.set_ylabel('PC2', fontsize = 15)\n",
    "    ax111.set_title('Hidden t-SNE', fontsize = 20)\n",
    "    for i, j in zip(seq, range(len(transformed))):\n",
    "        if i == 'a':\n",
    "            ax111.scatter(transformed[j][0], transformed[j][1], c='r', label='a')\n",
    "            ax111.annotate(str(j),(transformed[j][0], transformed[j][1]), color='r')\n",
    "        elif i == 'b':\n",
    "            ax111.scatter(transformed[j][0], transformed[j][1], c='b', marker='+', label='b')\n",
    "            ax111.annotate(str(j),(transformed[j][0], transformed[j][1]), color='b')\n",
    "        elif i == 'c':\n",
    "            ax111.scatter(transformed[j][0], transformed[j][1], c='g', marker='^', label='c')\n",
    "            ax111.annotate(str(j),(transformed[j][0], transformed[j][1]), color='g')\n",
    "        elif i == 'd':\n",
    "            ax111.scatter(transformed[j][0], transformed[j][1], c='k', marker='s', label='d')\n",
    "            ax111.annotate(str(j),(transformed[j][0], transformed[j][1]), color='k')\n",
    "        elif i == '#':\n",
    "            ax111.scatter(transformed[j][0], transformed[j][1], c='y', marker='*', label='#')\n",
    "            ax111.annotate(str(j),(transformed[j][0], transformed[j][1]), color='y')\n",
    "    #ax2.legend(bbox_to_anchor=(1, 1))\n",
    "    ax111.grid()\n",
    "    plt.show()\n",
    "        \n",
    "    if encoder_context is not None:\n",
    "        #---------Context PCA-----------------------------------------------------------------------------------\n",
    "        pca2 = principalComponents.fit_transform(encoder_context)\n",
    "    \n",
    "        fig222 = plt.figure(figsize=(8,8))\n",
    "        ax222 = fig222.add_subplot(111)\n",
    "        ax222.set_xlabel('PC1', fontsize = 15)\n",
    "        ax222.set_ylabel('PC2', fontsize = 15)\n",
    "        ax222.set_title('Context PCA', fontsize = 20)\n",
    "        for i, j in zip(seq, range(len(pca2))):\n",
    "            if i == 'a':\n",
    "                ax222.scatter(pca2[j][0], pca2[j][1], c='r', label='a')\n",
    "                ax222.annotate(str(j),(pca2[j][0], pca2[j][1]), color='r')\n",
    "            elif i == 'b':\n",
    "                ax222.scatter(pca2[j][0], pca2[j][1], c='b', marker='+', label='b')\n",
    "                ax222.annotate(str(j),(pca2[j][0], pca2[j][1]), color='b')\n",
    "            elif i == 'c':\n",
    "                ax222.scatter(pca2[j][0], pca2[j][1], c='g', marker='^', label='c')\n",
    "                ax222.annotate(str(j),(pca2[j][0], pca2[j][1]), color='g')\n",
    "            elif i == 'd':\n",
    "                ax222.scatter(pca2[j][0], pca2[j][1], c='k', marker='s', label='d')\n",
    "                ax222.annotate(str(j),(pca2[j][0], pca2[j][1]), color='k')\n",
    "            elif i == '#':\n",
    "                ax222.scatter(pca2[j][0], pca2[j][1], c='y', marker='*', label='#')\n",
    "                ax222.annotate(str(j),(pca2[j][0], pca2[j][1]), color='y')\n",
    "        #ax2.legend(bbox_to_anchor=(1, 1))\n",
    "        ax222.grid()\n",
    "        plt.show()\n",
    "        \n",
    "        #---------Context t-SNE---------------------------------------------------------------------------------\n",
    "        transformed2 = tsne.fit_transform(encoder_context)\n",
    "        fig333 = plt.figure(figsize=(8,8))\n",
    "        ax333 = fig333.add_subplot(111)\n",
    "        \n",
    "        ax333.set_xlabel('PC1', fontsize = 15)\n",
    "        ax333.set_ylabel('PC2', fontsize = 15)\n",
    "        ax333.set_title('Context t-SNE', fontsize = 20)\n",
    "        for i, j in zip(seq, range(len(transformed2))):\n",
    "            if i == 'a':\n",
    "                ax333.scatter(transformed2[j][0], transformed2[j][1], c='r', label='a')\n",
    "                ax333.annotate(str(j),(transformed2[j][0], transformed2[j][1]), color='r')\n",
    "            elif i == 'b':\n",
    "                ax333.scatter(transformed2[j][0], transformed2[j][1], c='b', marker='+', label='b')\n",
    "                ax333.annotate(str(j),(transformed2[j][0], transformed2[j][1]), color='b')\n",
    "            elif i == 'c':\n",
    "                ax333.scatter(transformed2[j][0], transformed2[j][1], c='g', marker='^', label='c')\n",
    "                ax333.annotate(str(j),(transformed2[j][0], transformed2[j][1]), color='g')\n",
    "            elif i == 'd':\n",
    "                ax333.scatter(transformed2[j][0], transformed2[j][1], c='k', marker='s', label='d')\n",
    "                ax333.annotate(str(j),(transformed2[j][0], transformed2[j][1]), color='k')\n",
    "            elif i == '#':\n",
    "                ax333.scatter(transformed2[j][0], transformed2[j][1], c='y', marker='*', label='#')\n",
    "                ax333.annotate(str(j),(transformed2[j][0], transformed2[j][1]), color='y')\n",
    "        #ax2.legend(bbox_to_anchor=(1, 1))\n",
    "        ax333.grid()\n",
    "        plt.show()\n",
    "        \n",
    "except KeyboardInterrupt:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
