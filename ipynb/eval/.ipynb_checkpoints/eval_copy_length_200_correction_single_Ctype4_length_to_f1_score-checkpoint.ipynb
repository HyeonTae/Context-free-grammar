{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Parameter\n",
    "- Attention = Luong\n",
    "- Teacher Forcing Ratio = 0.5\n",
    "- Layer = 1\n",
    "- Batch size = 32\n",
    "- Drop out = 0.2\n",
    "- Hidden unit = 50\n",
    "- Depth\n",
    "- Ctype\n",
    "- Epochs = 100\n",
    "- N = 100\n",
    "- Data = 100K\n",
    "- Deduplication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages\n",
    "\n",
    "import useful packages for experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hyeontae/hyeontae/venv/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import argparse\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import torchtext\n",
    "\n",
    "sys.path.append(os.path.dirname(os.path.abspath(os.path.dirname(os.path.abspath(os.path.dirname('__file__'))))))\n",
    "\n",
    "from models.encoderRNN import EncoderRNN\n",
    "from models.decoderRNN import DecoderRNN\n",
    "from models.encoderRNN_lenemb_add import EncoderRNN_lenemb_add\n",
    "from models.decoderRNN_lenemb_add import DecoderRNN_lenemb_add\n",
    "from models.encoderRNN_lenemb_cat import EncoderRNN_lenemb_cat\n",
    "from models.decoderRNN_lenemb_cat import DecoderRNN_lenemb_cat\n",
    "from models.encoderRNN_lenemb_cat_both import EncoderRNN_lenemb_cat_both\n",
    "from models.decoderRNN_lenemb_cat_both import DecoderRNN_lenemb_cat_both\n",
    "from models.encoderRNN_lenemb_add_order import EncoderRNN_lenemb_add_order\n",
    "from models.seq2seq import Seq2seq\n",
    "from loss.loss import Perplexity\n",
    "from dataset import fields\n",
    "from evaluator.evaluator_correction import Evaluator\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Log format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_level = 'info'\n",
    "LOG_FORMAT = '%(asctime)s %(levelname)-6s %(message)s'\n",
    "logging.basicConfig(format=LOG_FORMAT, level=getattr(logging, log_level.upper()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variable definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['single_Ctype4']\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 200\n",
    "f1_score_lists = []\n",
    "ctypes = [\"single_Ctype4\"]\n",
    "bidirectional = False\n",
    "print(ctypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hyeontae/hyeontae/venv/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Character type is : single_Ctype4\n",
      "[102, 104, 106, 108, 110, 112, 114, 116, 118, 120, 122, 124, 126, 128, 130, 132, 134, 136, 138, 140, 142, 144, 146, 148, 150, 152, 154, 156, 158, 160, 162, 164, 166, 168, 170, 172, 174, 176, 178, 180, 182, 184, 186, 188, 190, 192, 194, 196, 198, 200]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hyeontae/hyeontae/venv/lib/python3.6/site-packages/torch/nn/modules/rnn.py:54: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n",
      "/home/hyeontae/hyeontae/venv/lib/python3.6/site-packages/torch/nn/functional.py:1374: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length:102, Dev Loss:1.1803, F1 Score:0.0171\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-9a863138a9a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     56\u001b[0m               \u001b[0mfields\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'src'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'tgt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m               filter_pred=len_filter)\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0mdev_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq2seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         print(\"Length:%d, Dev Loss:%0.4f, F1 Score:%0.4f\\n\"\n\u001b[1;32m     60\u001b[0m                     % (length, dev_loss, f1_score))\n",
      "\u001b[0;32m~/hyeontae/Context-Free_Grammar5/evaluator/evaluator_correction.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, model, data)\u001b[0m\n\u001b[1;32m     48\u001b[0m                 \u001b[0minput_variables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_lengths\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'src'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mtarget_variables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_lengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'tgt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m                 \u001b[0mdecoder_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_hidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_variables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_lengths\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_variables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_lengths\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m                 \u001b[0mcorrect_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m                 \u001b[0;31m# Evaluation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/hyeontae/venv/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/hyeontae/Context-Free_Grammar5/models/seq2seq.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_variable, input_lengths, target_variable, target_lengths, teacher_forcing_ratio)\u001b[0m\n\u001b[1;32m     23\u001b[0m                               \u001b[0mencoder_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                               \u001b[0mfunction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                               teacher_forcing_ratio=teacher_forcing_ratio)\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/hyeontae/venv/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/hyeontae/Context-Free_Grammar5/models/decoderRNN_lenemb_add.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs, inputs_lengths, encoder_hidden, encoder_outputs, encoder_context, function, teacher_forcing_ratio)\u001b[0m\n\u001b[1;32m    189\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m                     \u001b[0mdecoder_input_length\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m                 \u001b[0mlen_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_input_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cuda:0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_attention\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;34m\"Bahdanau\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m                     \u001b[0mdecoder_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_hidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_attn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_step_BahdanauAtt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_hidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered"
     ]
    }
   ],
   "source": [
    "for i in ctypes:\n",
    "    f1_score_list = []\n",
    "    ctype = i\n",
    "    # Data load\n",
    "    train_path = \"../../data/copy_rand/correction_\" + ctype + \"/data_train.txt\"\n",
    "    \n",
    "    # Prepare dataset\n",
    "    src = fields.SourceField()\n",
    "    tgt = fields.TargetField()\n",
    "    max_len = 204\n",
    "    def len_filter(example):\n",
    "        return len(example.src) <= max_len and len(example.tgt) <= max_len\n",
    "    train = torchtext.data.TabularDataset(\n",
    "        path=train_path, format='tsv',\n",
    "        fields=[('src', src), ('tgt', tgt)],\n",
    "        filter_pred=len_filter\n",
    "    )\n",
    "    src.build_vocab(train)\n",
    "    tgt.build_vocab(train)\n",
    "    input_vocab = src.vocab\n",
    "    output_vocab = tgt.vocab\n",
    "    \n",
    "    # Prepare loss\n",
    "    weight = torch.ones(len(tgt.vocab))\n",
    "    pad = tgt.vocab.stoi[tgt.pad_token]\n",
    "    loss = Perplexity(weight, pad)\n",
    "    if torch.cuda.is_available():\n",
    "        loss.cuda()\n",
    "    \n",
    "    # Model\n",
    "    evaluator = Evaluator(loss=loss, batch_size=32)\n",
    "    hidden_size\n",
    "    print(\"Character type is : %s\" % ctype)\n",
    "    seq2seq = None\n",
    "    encoder = EncoderRNN_lenemb_add(len(src.vocab), max_len, hidden_size,\n",
    "                         bidirectional=bidirectional, rnn_cell='gru', variable_lengths=True)\n",
    "    decoder = DecoderRNN_lenemb_add(len(tgt.vocab), max_len, hidden_size * 2 if bidirectional else hidden_size,\n",
    "                         dropout_p=0.2, use_attention=\"Luong\", bidirectional=bidirectional, rnn_cell='gru',\n",
    "                         eos_id=tgt.eos_id, sos_id=tgt.sos_id)\n",
    "    seq2seq = Seq2seq(encoder, decoder)\n",
    "    if torch.cuda.is_available():\n",
    "        seq2seq.cuda()\n",
    "\n",
    "    for param in seq2seq.parameters():\n",
    "        param.data.uniform_(-0.08, 0.08)\n",
    "    \n",
    "    lengths = list(range(102, 201, 2))\n",
    "    print(lengths)\n",
    "    for length in lengths:\n",
    "        log_path = \"../../log/pth/gru_copy_rand_correction_ctype4_lenemb_add_encoder_decoder_\" + ctype + \"_model_save.pth\"\n",
    "        seq2seq.load_state_dict(torch.load(log_path))\n",
    "        seq2seq.eval()\n",
    "        dev_path = \"../../data/copy_rand/correction_\" + ctype + \"_N200/dev_length/data_test_length_\" + str(length) + \".txt\"\n",
    "        dev = torchtext.data.TabularDataset(\n",
    "              path=dev_path, format='tsv',\n",
    "              fields=[('src', src), ('tgt', tgt)],\n",
    "              filter_pred=len_filter)\n",
    "        dev_loss, _, _, f1_score = evaluator.evaluate(seq2seq, dev)\n",
    "        print(\"Length:%d, Dev Loss:%0.4f, F1 Score:%0.4f\\n\"\n",
    "                    % (length, dev_loss, f1_score))\n",
    "        \n",
    "        f1_score_list.append(f1_score)\n",
    "        \n",
    "    f1_score_lists.append(f1_score_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,7))\n",
    "plt.plot(lengths, f1_score_lists[0], '-o', LineWidth=3, label=\"GRU LenEmb Add\")\n",
    "plt.legend(loc=\"best\", fontsize=12)\n",
    "plt.xlabel('Length', fontsize=24)\n",
    "plt.ylabel('F1 Score', fontsize=24)\n",
    "plt.ylim([0, 1.1])\n",
    "#plt.savefig('../../log/plot/copy_length_correction_length_to_f1_score/copy_length_correction_single_Ctypes4_length_to_f1_score.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 1.0, 0.999131190269331, 0.9963355048859935, 0.9978902953586498, 0.9987928536938677, 0.9992163009404389, 0.9989304812834224, 0.9976669582968796, 0.9971527997469155, 0.9912985274431058, 0.9898813677599442, 0.9816692667706708, 0.9738589211618257, 0.9676573426573426, 0.9489911584674676, 0.9319032177600399, 0.9082020640956002, 0.8744686880136016, 0.84805869764598, 0.8182097816056598, 0.7985964912280702, 0.7578096288129366, 0.7371360191463902, 0.691304347826087, 0.6295620437956204, 0.591715976331361, 0.5368852459016393, 0.5014475969889982, 0.4265644955300128, 0.39452054794520547, 0.3695501730103807, 0.3320031923383879, 0.295221843003413, 0.26601941747572816, 0.23838383838383836, 0.19277108433734944, 0.16303099885189437, 0.13089005235602094, 0.10296010296010297, 0.1143740340030912, 0.09969788519637462, 0.0553935860058309, 0.04684684684684685, 0.048964218455743884, 0.024489795918367346, 0.03131991051454139, 0.033402922755741124, 0.009132420091324202, 0.022421524663677125]\n",
      "[1.0, 1.0, 1.0, 1.0, 0.9994725738396625, 0.99987929993965, 0.9989550679205852, 0.9966582007752974, 0.9932944606413994, 0.9924122668352829, 0.9849347171074657, 0.9774829813230931, 0.9748488984207448, 0.9720323182100684, 0.9617653484815382, 0.9553793884484711, 0.9540918163672655, 0.9218241042345277, 0.9236879432624113, 0.9131754705525197, 0.9035409035409036, 0.8726643598615917, 0.846433770014556, 0.82265625, 0.8233809924306139, 0.5145454545454545, 0.06255835667600372, 0.03347280334728033, 0.019184652278177457, 0.019775873434410018, 0.019131714495952905, 0.012288786482334871, 0.001838235294117647, 0.006066734074823053, 0.011641443538998836, 0, 0.002386634844868735, 0, 0, 0.002277904328018223, 0, 0, 0.002185792349726776, 0, 0, 0, 0, 0, 0, 0]\n",
      "[1.0, 1.0, 1.0, 1.0, 1.0, 0.9997585707387735, 1.0, 1.0, 1.0, 0.9998417971839899, 0.999330655957162, 0.9993021632937893, 0.9978544958065146, 0.9973023448848309, 0.9958433603150295, 0.9925153095940122, 0.9912609238451936, 0.9937550909584579, 0.9889674681753889, 0.9838463882962512, 0.9853300733496332, 0.9765193370165746, 0.9524500907441016, 0.9448329448329449, 0.9416666666666667, 0.37371479660259277, 0.06446140797285835, 0.01352493660185968, 0.014931927975406236, 0.019102196752626553, 0.018691588785046728, 0.011161846778285134, 0.004514672686230248, 0.00966183574879227, 0.00844475721323012, 0.008888888888888889, 0.004618937644341801, 0.005176876617773943, 0.0037071362372567192, 0.005555555555555556, 0.004282655246252677, 0.006295907660020986, 0.005893909626719057, 0.004848484848484849, 0.0023419203747072604, 0.0025575447570332483, 0.0028985507246376808, 0.010596026490066225, 0.008862629246676513, 0]\n",
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9997387669801463, 0.9967914438502674, 0.9911039813329443, 0.982123081790856, 0.9650092081031307, 0.9519146703969225, 0.9414519906323184, 0.912251655629139, 0.9097678493210688, 0.8762769580022701, 0.8422894276430892, 0.812994812994813, 0.784302492122601, 0.7677519379844961, 0.7465495608531995, 0.7068532472192323, 0.6441598758246023, 0.6048109965635738, 0.563525550867323, 0.23275862068965514, 0.026143790849673203, 0.005852231163130943, 0.0038461538461538455, 0.00606060606060606, 0, 0, 0.0013333333333333333, 0.0027378507871321013, 0, 0, 0, 0, 0, 0, 0, 0.001926782273603083, 0.0018939393939393938, 0, 0, 0, 0, 0, 0, 0]\n",
      "[1.0, 0.9947643979057591, 1.0, 1.0, 1.0, 1.0, 0.9994775339602926, 0.9991978609625668, 0.9966457634534053, 0.9936668777707409, 0.9840950945923322, 0.9823519133321684, 0.9779253760500097, 0.9682374922150716, 0.955453149001536, 0.9332728098048115, 0.9202207727044657, 0.900244631693395, 0.8804564907275321, 0.8526607197785296, 0.8463911165946947, 0.8162124388539482, 0.7876106194690266, 0.757080175508576, 0.6919758412424505, 0.4426002766251729, 0.3818525519848771, 0.2055164954029205, 0.08685446009389673, 0.04333970681963034, 0.0266844563042028, 0.013764624913971095, 0.020249221183800625, 0.010300429184549357, 0, 0.008316008316008315, 0.006681514476614699, 0.004784688995215311, 0.002728512960436562, 0, 0.002840909090909091, 0.002751031636863824, 0.0024906600249066002, 0.005961251862891207, 0.0028653295128939827, 0.0030257186081694403, 0.003110419906687403, 0, 0, 0]\n",
      "[1.0, 1.0, 0.9991326973113617, 0.9985746283852575, 0.9989451476793249, 0.9995171414775471, 0.995822454308094, 0.9973262032085561, 0.988773873742528, 0.9791073124406457, 0.9793935332551515, 0.963855421686747, 0.9596255119953188, 0.9244186046511629, 0.9044278825076721, 0.8273496455522524, 0.7877417734237628, 0.7015047879616962, 0.694309408064055, 0.7404674046740468, 0.6703738029039233, 0.677170868347339, 0.7125506072874493, 0.7105678233438485, 0.7282793867120955, 0.13470533208606172, 0.06352357320099256, 0.0405982905982906, 0.019755955839628123, 0.016082711085583, 0.009291521486643438, 0.013613159387407828, 0.012048192771084336, 0.004944375772558714, 0.006944444444444444, 0, 0, 0.0014992503748125937, 0, 0.0016168148746968473, 0.0074487895716946, 0, 0, 0.0021810250817884407, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(f1_score_lists[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
